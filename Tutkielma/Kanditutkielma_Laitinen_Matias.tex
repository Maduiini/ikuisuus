% !TeX encoding = utf8
%
% [ Tiedostossa käytetty merkistö on utf8, vaihtoehtoisesti voisi olla esim.]
% [ ISO 8859-1 eli Latin 1. Ylläoleva rivi ]
% [ tarvitaan, jos käyttää MiKTeX-paketin mukana tulevaa TeXworks-editoria. ]
%
% TIETOTEKNIIKAN KANDIDAATINTUTKIELMA
%
% Yksinkertainen LaTeX2e-mallipohja kandidaatintutkielmalle.
% Käyttää Antti-Juhani Kaijanahon kirjoittamaa gradu3-dokumenttiluokkaa.
%
% Jos kirjoitat pro gradu -tutkielmaa, tee mallipohjaan seuraavat muutokset:
%  - Poista dokumenttiluokasta optio bachelor .
%  - Poista makro \type .
%  - Lisää suuntautumisvaihtoehto makrolla \studyline .
%  - Lisää tieto ohjaajasta makrolla \supervisor .

\documentclass[utf8,bachelor,manualbib]{gradu3}

\usepackage{palatino} % valitaan oletusfonttia hieman tyylikkäämpi fontti

\usepackage{graphicx} % tarvitaan vain, jos halutaan mukaan kuvia
\usepackage{amsmath}  % tarvitaan käytettäessä monimutkaisten matemaattisten kaavojen ja \eqref-kaavaviittauksen yhteydessä
\usepackage{url} % tarvitaan \url-komentoa varten
\usepackage{booktabs}

% Otetaan käyttöön author-date-järjestelmän mukaiset lähdeviittaukset:
\usepackage{natbib}
% Vaihdetaan kirjoittajan nimen ja vuosiluvun väliseksi erottimeksi
% välilyönti (oletuserottimena on pilkku):
%\bibpunct{(}{)}{;}{a}{}{,}


% HUOM! Tämän tulee olla viimeinen \usepackage koko dokumentissa!
\usepackage[bookmarksopen,bookmarksnumbered,linktocpage]{hyperref}

%\addbibresource{viite.bib}% Lähdetietokannan tiedostonimi
%http://www.tex.ac.uk/tex-archive/macros/latex/exptl/biblatex-contrib/biblatex-chicago/latex/biblatex-chicago.sty
%http://www.tex.ac.uk/tex-archive/macros/latex/contrib/etoolbox/etoolbox.sty
%http://mirrors.med.harvard.edu/ctan/macros/latex/contrib/biblatex/latex/biblatex.sty
%http://ctan.mackichan.com/macros/latex/contrib/biblatex/latex/biblatex2.sty
%http://mirror.hmc.edu/ctan/macros/latex/contrib/logreq/logreq.sty
%https://github.com/Martin-Rotter/qt-survival-guide/blob/master/logreq.def

\begin{document}

\title{SV- ja EV-järjestelmät kaupallisessa ilmailussa}

\translatedtitle{Synthetic and Enhanced Vision Systems in Commercial Aviation}

%\studyline{}
\avainsanat{SVS, EVS, ilmailu, näkyvyys, HUD, HDD, lentäminen, lentoturvallisuus, IFR, NextGen, NGATS, EVO}
\keywords{SVS, EVS, synthetic vision, enhanced vision, aviation, HUD, HDD, flying, safety, visibility, IFR, NextGen, NGATS, EVO}
\tiivistelma{Tähän tulee tiivistelmä (tausta, tavoite, tulokset, johtopäätökset).
}
\abstract{Tähän tulee englanninkielinen versio tiivistelmästä.
}

\author{Matias Laitinen}
\contactinformation{\texttt{matias.laitinen@gmail.com}}
% jos useita tekijöitä, anna useampi \author-komento
%\supervisor{TODO}
% jos useita ohjaajia, anna useampi \supervisor-komento
%\type{bachelor} % tämän makron oletus on "pro gradu -tutkielma" ja bachelor-optiolla kandidaatintutkielma

\maketitle
  
\mainmatter

\chapter{Johdanto}

Viime aikoina lentoturvallisuus on noussut useasti esille medioissa, kun sekä harraste- että kaupallisen ilmailun puolella on tapahtunut monenlaisia lento-onnettomuuksia tai ilmailun vaaratilanteita. Nämä onnettomuudet aiheutuvat useimmiten inhimillisistä virheistä. Tutkimuksen tavoitteena on ottaa selvää, millä eri tavoin olisi keinotekoisia näköjärjestelmiä käyttämällä mahdollista ehkäistä lento-onnettomuuksia ja parantaa lentäjän tilannetietoisuutta, etenkin huonon näkyvyyden olosuhteissa. Tällaiset järjestelmät ovat olleet sotilaspuolen käytössä jo pitkän aikaa, mutta siviili-ilmailussa niitä hyödynnetään vasta melko vähän. Kartoittamalla näiden järjestelmien kustannuksia ja käytettävyyttä saadaan toivottavasti tehtyä jonkinlaisia johtopäätöksiä niiden soveltuvuudesta käytäntöön. TODO: Kerro paremmin ja laita viitteet kuntoon.

The United States air transportation system is undergoing a transformation to accommodate a projected 3-fold
increase in air operations by 2025.1 Technological and systemic changes are being developed to significantly
increase the capacity, safety, efficiency, and security for this Next Generation Air Transportation System
(NGATS). One of the key capabilities envisioned to achieve these goals is the concept of Equivalent Visual
Operations (EVO), whereby Visual Flight Rules (VFR) operational tempos and also, perhaps, operating
procedures (such as separation assurance) are maintained independent of the actual weather conditions. One
methodology by which the goal EVO might be attainable is to create a virtual visual flight environment for
the flight crew, independent of the actual outside weather and visibility conditions, through application of
Enhanced Vision (EV) and Synthetic Vision (SV) technologies. \citep{baileyym2007}

\chapter{Ilmailu ja näkyvyys}

\section{Näkyvyyden vaikutus lennon aikana}

Näkyvyys on lentokoneen ohjaajalle tärkeää lennettäessä lähellä maata, etenkin laskeutumisen aikana. Sen vuoksi huonot näkyvyysolosuhteet aiheuttavat suuria rajoitteita lentotoiminnalle. \cite{mollersachs1994} Pilotin lentonäkyvyyteen vaikuttavat monet meteorologiset olosuhteet, kuten pimeys, pöly, sumu ja sade \citep{wickens2009} Erityisesti sumuisissa olosuhteissa näkyvyys voi huonontua dramaattisesti ja ulkomaailman yksityiskohtia on miltei mahdotonta erottaa \citep{beiergemperlein2004}.

Kaikilla lentokentillä toimittaessa ovat voimassa tietyt näkyvyysrajoitukset. Kentillä, joilla on käytössä esimerkiksi ILS:n kaltaisia lähestymisapuja, on tietty minimi, josta tulee olla mahdollista jatkaa lähestymistä visuaalisesti. Vakavimmillaan rajoitukset vaikuttavat kentillä, joilla ei tällaisia järjestelmiä ole käytössä. Nämä säännöt ovat voimassa, vaikka lähestyvällä koneella olisi käytössään nykyaikaiset mittari- ja navigointilaitteet.~\cite{mollersachs1994}

Model calculations have been performed in the thermal
infrared regions 3–5 [micro]m and 8–12 [micro]m to assess the use of IR
cameras in low visibility conditions, especially fog, for air
traffic during landing approaches. The investigations are carried
out with the atmospheric radiative transfermodelMODTRAN
version 4.0 and the thermal imaging model TTIM.
The ICAO standard visual range categories CAT I, II, IIIa
and IIIc are used as bench marks. The influence on visibility
of various climatic and seasonal meteorological conditions,
aerosol types and target parameters, such as temperature and
size, is taken into account. The simulation uses sensor parameters
of a standard uncooled IR camera type Thermovision
570, which is utilized for flight measurement at DLR
within the Enhanced Vision Project ADVISE. The instantaneous
field of views are 0.65 mrad or 1.3 mrad respectively.
The results can be summarized as follows: At CAT I
conditionswith a visual range 1220m both IR spectral bands
can achieve IR detection ranges, in terms of the defined
NEDT = 0.15 K, from 3 to 10 km. The IR detection range
is noticeable improved for all climatic zones, seasons and
types of aerosols. The lowest IR detection range is met in
the tropics at sea level with high absolute humidity. In the
thermal IR 8–12 [micro]m the most favourable terms occur at
subarctic winter with low humidity. The IR detection range
referring to small targets with a size of 2–5 m is limited
due to the sensor MTF. For large targets such as the runway
the atmospheric influence is the limiting factor for the IR
detection range.
For CAT II conditions at moderate fog, with 610 m
visual range, only the thermal IR region 8–12 [micro]m enables to
improve of the detection range up to 1–2 km, which means
CAT II conditions can be improved to CAT I. The selected
spatial and radiometric resolution of the IR sensor has to
fit to the size and temperature difference of the target to be
detected. The supposed IR sensor requires for a target with
dimensions 5 m x 5 m a minimum temperature difference
of 1 K to the ambient background.
For categories CAT IIIa and IIIc with dense fog and visual
ranges of 300 m to 100 m and less, there is no improvement
achievable utilizing IR cameras. The atmosphere is the
limiting factor in all spectral bands from the visible to the
IR. Even a large initial radiation temperature difference of
100 K and more cannot improve the IR detection range
significantly. At this atmospheric conditions an IR sensor
even with a smaller NEDT, which means higher radiometric
resolution, would only enhance the inhomogeneities of the
atmospheric path radiance and not improve the IR detection
range of the target. In this case an imaging radar system
is necessary in order to improve the visibility for landing
approaches. However for a taxiing aircraft on ground it
makes sense to use IR cameras even at dense fog conditions
to improve detection and recognition of obstacles such as
persons, vehicles and ground installations within the range
of the IR detection range.
The validation of the simulation results with flight measurements
is still in progress. A comparison of measured and
simulated data will be presented in a succeeding paper and a
final report. \citep{beiergemperlein2004}

The ability of a pilot to ascertain critical information through visual perception
of the outside environment can be limited by various weather phenomena, such as
rain, fog, and snow. Since the beginning of flight, the aviation industry has developed
various devices to overcome these low-visibility limitations. These include
attitude indicators, navigation aids, instrument landing systems (ILS), moving
map displays, and terrain awareness warning systems (TAWS). All of the aircraft
information display concepts developed to date, however, still require pilots to
continuously perform information acquisition and decoding to update and maintain
their mental model to “stay ahead” of the aircraft when outside visibility is reduced.
The NASA SVS project is based on the premise that better pilot SA during
low-visibility conditions can be achieved by reducing the steps required to build a
mental model from disparate pieces of data through the presentation of how the
outside world would look to pilots if their visibility was not restricted. \citep{prinzel2004}

The Flight Safety Foundation (FSF) data show that almost 60% of all commercial
aircraft crashes occurred during the approach and landing phases of flight. Controlled
flight into terrain (CFIT) is the dominant accident type and is responsible
for more than half of all commercial aviation fatalities to date (Etherington, Vogl,
Lapis, \& Razo, 2000). CFIT crashes are usually associated with a loss of position
and situation awareness (SA) during the approach and landing phases of a flight, as
pilots lose their perception of aircraft path, heading, altitude, and positions with relation
to the surrounding environment. Synthetic vision information systems
(SVIS) may well be a key technology in reducing CFIT crashes. SVIS may also be
a potential solution to overcome airspace limitations. The present airway-based
airspace system is nearing its capacity limits, especially in some terminal areas.
The slightest imbalance in terms of weather conditions or equipment problems can
bring the system to a near halt in crowded terminal areas. Air traffic is expected to
double in the next decade, and if there are no additional technological advances to
increase efficiency and provide methods to redesign the airspace system, there will
be a major capacity problem in the future. \citep{schnell2004}

\section{Näkyvyyden vaikutus maatoimintaan}

Prinzelin ym. (\citeyear{prinzel2013}) tutkimuksen ja kokemuksen perusteella huonon näkyvyyden aiheuttamat toiminnan hidastumiset ja viivästykset maatoiminnassa ovat kasvavasti vaikuttamassa myös ilmatilankäytön viiveisiin. Huonon näkyvyyden olosuhteissa ohjaajien ja ajoneuvonkuljettajien tulee säilyttää tilannetietoisuutensa varmistaakseen, että maatoiminta on turvallista ja tehokasta.

Esimerkiksi FAA:n vuoden 2010 turvallisuusselvityksen mukaan 52 928 316 maatoimintaan liittyvän tapahtuman aikana tapahtui 951 kiitotiepoikkeamaa, joista 12 oli vakavia. Vaikka tämä luku on suhteessa pieni, kiitotiepoikkeamalla voi olla tuhoisat seuraukset. Suurimpana syynä näissä tapauksissa oli ohjaajan inhimillinen erehdys (63 \%). Tilannetietoisuutta parantamalla voitaisiin siis saada merkittävästi vähennettyä kiitotiepoikkeamien määrää. \citep{prinzel2013}


\chapter{SV- ja EV-järjestelmät}

Keinonäköjärjestelmillä (SVS, Synthetic Vision Systems) tarkoitetaan keinotekoisen ympäristökuvan luomista tietokoneella. Kuva luodaan yhdistäen lentoasento- ja tarkkuusnavigointijärjestelmiltä sekä maasto- ja estetietokannoista saatua lennon kannalta tärkeää tietoa. SV-järjestelmillä saadaan huomattavia parannuksia maastoestetietouteen ja se vähentää tahattomien maahantörmäysten (CFIT, Controlled Flight Into Terrain) riskiä nykyiseen ohjaamoissa käytettävään teknologiaan verrattuna. \citep{baileyym2007}

Parannellun näön järjestelmillä (EVS, Enhanced Vision Systems tai EFVS, Enhanced Flight Vision Systems) tarkoitetaan elektronisen apuvälineen, kuten lämpökameran (FLIR, Forward-Looking Infrared) tai millimetritutkan (MMWR, Millimeter Wave Radar) avulla näytettyä kuvaa ulkomaailmasta \citep{baileyym2007}. Möller ja Sachs \citeyearpar{mollersachs1994} kertovat, optisten järjestelmien, kuten lämpökameran, olevan passiivinen laite, jolla voidaan muodostaa ympäristökuva ilman tietoa etäisyyksistä. Tutkalla sen sijaan saadaan aktiivisesti etäisyystietoa ympäristöstä, mutta tavallisen näköistä kuvaa on vaikea muodostaa.  Jo Nordwallin \citeyearpar{nordwall1993} mukaan heijastusnäyttö(HUD, Head-Up Display)-lämpökamera -yhdistelmällä saavutetaan esimerkiksi sumussa huomattavasti parempi kuva ynpäristöstä, kuin mitä paljaalla silmällä voitaisiin saavuttaa. 

SV-EV yhdistäminen, tähän kuva \citep{mollersachs1994}
Distance Dependent Resolution
The number of meshes in the field of view increases with
the square of the visibility range. A realtime drawing of the
polygons may not be possible for a large visibility range.
Therefore, the field of view is divided into several areas with
different Levels Of Details (LOD). Due to the regular elevation
grid, the grid distance can be doubled from one LOD area to
the next one. The areas for different LODs are calculated in
the same way as the field of view with Eqs. (2) and (3), but
using different distance restricted t-parameters. The points of
the last grid line with a higher LOD have to be moved to the
first grid line of the adjacent lower LOD to avoid gaps in the
terrain at the boundaries of areas with different LODs. This
linear interpolation can be done on-line.
are still a remaining task when considering a rough terrain and
using a graphic system the drawing speed of which is not fast
enough.
Problems with popping up hills at the boundaries of the LODs
Fig. 13. Terrain with DFAD and Overlaid Grid
LIUU
/2000
1800
I -ill- c
,801
-I r
Fig. 14. Conventional Primary Flight Display
Fig. 12. Terrain Surface without DFAD
Requirements Concerning Pilots Orientation
Fig. 15. Integrated Flight Display
One point concerns the number of displayable objects. This
number is confined because of limitations in graphic hardware
performance and memory capacity. Another point is related to
texturing. Present computer hardware which is suited for use
32
onboard of an aircraft has also no real-time texture capabilities.
The lack of texturing may cause difficulties for the pilot in
estimating the height above ground when the terrain surface is
LOD \citep{mollersachs1994}

Natural information implies the method of information acquisition by the pilot
similar to that experienced in visual meteorological conditions (VMC) by looking
out the window. Visual altitude judgment is an example of natural information.
54 PRINZEL ET AL.
Downloaded by [Jyvaskylan Yliopisto] at 06:38 22 December 2013
Coded information implies some type of information presentation to the pilot that
requires interpretation to comprehend the actual value. An example of coded information
is altimeter reading. Helmetag, Kaufhold, Lenhart, and Purpus (1997) argued
that it is very important to give the pilot information required to maintain SA
in low-visibility conditions and that natural information presentation is intuitive
and able to be perceived in a much more rapid manner than coded information.
SVS displays provide exactly such a natural presentation of the outside world with
proximity compatible, integrated in \citep{prinzel2004}

Synthetic vision technology may allow the issues associated with limited visibility
to be solved with a visibility-based solution, making every flight the equivalent of
a clear daylight operation, which will help improve SA and support proper development
of the pilots’ mental model. Therefore, SVS can have a significant impact
on improving aviation safety because limited visibility represents the single greatest
contributing factor in many fatal airline accidents worldwide (Boeing, 1996).\citep{prinzel2004}

The aviation safety benefits of synthetic vision alone are reason enough to pursue
the technologies but, due to the costs associated with such a system, it must also
present operational and economic benefits. NASA anticipates that SVS technology
could serve to increase national airspace system capacity by providing the potential
for increased VMC-type operations even under Category IIIb weather conditions
(Williams et al., 2001). Benefits would include: (a) reduced runway
occupancy time in low visibility; (b) reduced departure and arrival minimums; (c)
better allowance for converging and circling approaches, especially for dual and
triple runway configurations; (d) reduced interarrival separations; and (e) independent
operations on closely spaced parallel runways. A cost–benefit analysis of
10 airports (DFW, ORD, LAX, ATL,DTW, MSP, EWR, SEA, LGA, and JFK) calculated
the average cost savings to airlines for the years 2006 to 2015 to be 2.25
billion (Williams et al., 2001). \citep{prinzel2004}

Synthetic vision information systems (SVIS) are the next generation of cockpit display
systems that will become an integral part of the commercial flight deck in the future.
The goal of this study was to evaluate SVIS against conventional glass cockpit
displays to assess whether or not SVIS can improve pilot performance, situation
awareness (SA), and workload \citep{schnell2004}

The SVIS
80 SCHNELL, KWON, MERCHANT, ETHERINGTON
Downloaded by [Jyvaskylan Yliopisto] at 07:01 22 December 2013
displays consist of the tactical pathway display (essentially an enhanced PFD)
with synthetic terrain, and a 3-D map display that presents strategic navigation information.
The SVIS displays used in this study were originally developed by
Delft Technical University in the Netherlands in collaboration with Rockwell Collins.
The combination of a pathway tunnel and a flight path predictor cue is a fairly
new approach that provides enhanced guidance information to the crew, providing
them with a preview of the situation ahead. The SVIS displays incorporate the
functions of the conventional PFD and navigation display (ND; displayed on the
MFD), and in addition supplement the flight crew with the task-oriented situation
data and guidance needed to fly complex, curved paths. \citep{schnell2004}

An HUD is a projected display of symbology on a transparent screen. As can be
seen in Figure 1, the symbology is superimposed over the pilot’s forward field
of view, enabling him or her to monitor primary flight information while maintaining
a view of the outside world. The result is an opportunity for less time
“head down” looking at instrumentation approximately 10 degrees below the line of
sight, and more time maintaining visual contact with the outside environment.
The first use of anHUDwas for gun sights in the 1950s. These early HUDs were
used for aiming and not as a flight instrument. In 1960, the Hawker Siddeley Buccaneer
included the first operational HUD designed for use as a piloting instrument
(Weintraub\&Ensing, 1992). ThisHUDconsisted of a horizon and a reference symbol
of an aircraft. Altitude and speed values were digitally displayed, with the Flight
Director providing rough flight path guidance information. TheHUDsymbology of
the Buccaneer provides the basis for that used in most HUDs today.
HUDs are currently used as a visual aid to assist during two main landing situations,
namely the visual approach and the transition from instrument meteorological
conditions to a visual landing. The use of HUD during the various phases of
flight is mandated by the airline company operating the aircraft in which the HUD
is installed. The four advantages for the incorporation of HUDs into modern aircraft
that have been proposed are a reduction of head-down time during critical
stages of flight, a potential reduction in the need to refocus the eyes from the near
to the far domain (from instrumentation to the external world), an improvement in
awareness of the external domain, and an improvement in the quality of the instru-mentation display by comparison to conventional displays based on dials and
gauges (May \& Wickens, 1995).
Studies of flight performance have shown advantages for HUDs over traditional
head-down displays (HDDs), including superior flight path maintenance
and higher precision landings (see Fischer, Haines, \& Price, 1980; Naish, 1964).
Furthermore, for some airports and aircraft types, HUDs enable lower visibility
takeoffs and landings than previously possible. This can provide significant cost
savings for airlines. However, potential problems have also emerged. Some of the
early problems relating to design appear to have been resolved, but there are a
number of cognitive issues that are still a matter of debate and research. These include
the effects of divided attention and cognitive tunneling, and spatial disorientation
and unusual attitude recovery. These issues are reviewed in later sections. \citep{crawford2006}

EVS/SVS
EVSs are designed to increase safety in low-visibility conditions. EVSs can be
added to both HUDs and HDDs, providing the pilot with infrared-derived visual
cues of the external scene, including terrain and traffic. The pilot sees the
real-world runway even when it is obscured by poor weather conditions. The
EVS also enables views of surrounding terrain in poor lighting and weather conditions.
This may help to prevent controlled flight into terrain.
HEAD-UP DISPLAYS 15
Downloaded by [Jyvaskylan Yliopisto] at 07:02 22 December 2013
The use of EVS is limited during periods of heavy rain, fog, and dust. Furthermore,
as infrared only shows thermal differences, the images can be confusing during
certain conditions such as when objects within a scene are of an equal
temperature.
SVS is a different flight display system developed by Rockwell Collins and
NASA. It provides a conformal view of the world outside using the EGPWS database
to portray a picture of terrain, obstructions, and airports. SVS uses highway-
in-the-sky software, giving pilots visual cues and flight path guidance. As the
images provided are database derived, it is possible that important information is
not available when needed, such as a new construction. Furthermore, processing
latency or database integrity issues may lead to confusion when the pilot breaks
through cloud cover and the image from the HUD is not the same as that provided
by the SVS.
Researchers are currently exploring the possibility ofcombiningEVSandSVSto
produce an enhanced synthetic vision system. With both systems used in combination,
the images, which will include possible hazardous traffic, will give the pilot the
sameinformation aswouldbe available for a daylight, clear weather visual flight.As
both systems can be presented on anHUDtogether, human factor design principles,
pilot performance, problems, and safety concerns will need to be investigated. \citep{crawford2006}

]Head-up displays (HUDs) are being introduced into general aviation in part due to
the advantages shown in both military and civilian aviation. There are general
findings of the success of HUDs when these are compared with either the typical
instrumentation panel or the same symbology presented in the head-down position.
llUDs have continually revealed performance benefits for flight-path maintenance
(Fischer, Haines, \& Price, 1980; Lauber, Bray, Harrison, Hemingway, \& Scott, 1982; Wickens \& Long, 1995) and detection of expected incidents or warnings
(e.g., detecting the runway on approach) occurring either in the scene or on the
symbology itself (Fischer, 1979; Larish \& Wickens, 1991; Wickens \&Long, 1995).


\section{Käyttö lennon aikana}

2.1 Integrated and Fused Synthetic and Enhanced Vision Systems Concepts
The complementary capabilities of SV and EV have been well-recognized6 with the premise that7 “the
strengths of enhanced system can compensate for the deficiencies in the synthetic system and that the
strengths of synthetic system can compensate for the deficiencies in the enhanced vision system.” While
these goals are obvious, optimal methods and capabilities are not on hand.
2.2 Previous Research
Several studies8-10 have shown that the optimal combination of SV and EV technology likely uses the direct
display of SV to the flight crew without direct display of EV, but instead, using EV “behind the glass” for
navigation error detection, database integrity monitoring, and real-time obstacle/object detection. Image
processing performs these functions automatically without intervention by the flight crew. This arrangement
provides a highly usable display presentation (i.e., SV) that is impervious to the actual weather and visibility
conditions, yet if un-charted obstacles, database errors or navigation errors are detected by the EV running in
the background, the situation is annunciated, and almost “perfect” decision-making by the pilot occurs.8-10 In
fact, the study conclusion from Parrish8 – “SVS concepts should not be implemented without incorporating
image-processing decision aides for the pilot” – launched a 5 year effort at NASA and elsewhere developing
SV Systems (SVS) enabling technologies for database integrity monitoring and EV object detection. 11-15
While degrees of success in developing these decision aids have been met, technology for “perfect” object
detection and database/navigation error detection does not yet exist. Further, there may always be gaps which
may still warrant flight deck procedures and human interventions for integrity and error checks.
\citep{baileyym2007}

Present federal airways, on en route charts, are depicted as primarily straight
lines between ground-based navigation stations (VORs). To go from Point A to
Point B, a flight crew is generally expected to file a flight plan following federal
airways (Victor airways or Juliet airways). The result is a routing system that produces
flight plans that look more like driving on roads and highways than flying in
airspace. Quite often Points A and B are not neatly connected by a straight line, but
rather, the crew has to make several turns and change airways at intersections. The
present airway system, however, has some advantages. Following an airway at or
above the minimum enroute altitude ensures terrain clearance and adequate radio
reception of the navaids. Pilots can request direct flight paths if they ensure adequate
clearance with terrain. SVIS is a concept that may help crews to increase
their terrain awareness when operating en route and in terminal areas.
Most present approaches involve straight segments between waypoints. However,
modern technology allows for the execution of curved approaches in four dimensions
(three spatial dimensions and the time dimension). Navigation technology
based on global positioning satellites, combined with SVIS, will enable the
design of curved and constant descent approaches that may be more efficient than
navaid-based, straight-line approaches with step-down fixes. Although technically
feasible, such complex curved paths cannot easily be communicated to and
managed by flight crews with conventional primary flight displays (PFDs) and
multifunction displays (MFDs). Curved approaches, especially when including
the time dimension, cannot easily be conveyed in verbal or paper format.
The SVIS displays evaluated in this study allow communication of the desired
curved flight path by means of a tunnel (corridor) that the pilot needs to follow.
SVIS is based on the concept of a tunnel in the sky depicting a three-dimensional
view of the world and the desired flight path (Barrows \& Powell, 1999). \citep{schnell2004}

Ehkä kuvia tähän vielä \citep{schnell2004}

\section{Käyttö maatoiminnassa}

NASA is conducting research, development, test, and evaluation of flight deck display technologies that may significantly enhance the flight crew's situation awareness, enable new operating concepts, and reduce the potential for incidents/accidents for terminal area and surface operations. The technologies that form the backbone of the BTV operational concept include: surface and airport moving maps; head-up and head-worn displays; four dimensional trajectory (4DT) guidance algorithms; digital data-link communications; synthetic and enhanced vision technologies; and traffic conflict detection and alerting systems (Bailey, Prinzel, Young, and Kramer, 2011; Prinzel et al., 2011). Preliminary research is described assessing a subset of these technologies in comparison to current-day low visibility surface operations. \citep{prinzel2013}

Maatoiminnassa lennonjohdon, koneiden ohjaajien sekä ajoneuvonkuljettajien tilannetietoisuutta pyritään pitämään yllä tarjoamalla visuaalisia merkkejä omasta sijainnista, kulkureiteistä ja tilasta kiito- ja rullausteillä, odotuspaikoilla ja asematasoilla. Tämä hoidetaan esimerkiksi valojen, merkintöjen ja opasteiden avulla. Tällaisia järjestelmiä kutsutaan nimellä Surface Movement Guidance and Control System (SMGCS). \citep{prinzel2013}

Tilannetietoa ylläpitäviä järjestelmiä voitaisiin myös käyttää ohjaamoissa. Tällaisista järjestelmistä voisi Prinzelin ym. \citeyearpar{prinzel2013} mukaan olla hyötyä, varsinkin henkilöstön näkyvyyden parantamisessa keinotekoisesti sekä tilannetietoisuuden (paikka- ja reittitiedon ja mahdollisesti myös liikenne- ja estetiedon) parantamisessa erilaisten karttajärjestelmien avulla. Etenkin yöllä, tai savun tai pölyn haitatessa näkyvyyttä EV-järjestelmät voivat auttaa pilottia toimimaan turvallisemmin maassa \citep{prinzel2013}. Hooeyn \& Foylen \citeyearpar{hooey2007} tutkimuksen mukaan 17\% huonossa näkyvyydessä tai yöllä tapahtuneessa rullauskokeessa tuli esille navigointivirheitä, jotka saatiin korjattua liikkuvien lentokenttäkarttojen (Airport Moving Map, AMM) avulla.

Synthetic Vision information provides also a menas for enhancing poor visibility operations of aircraft when moving on the ground. There are only simple or marginal optical aids for surface movement.
For example, such aids concern lighting of center lines of
taxiways, stop and clearance bars or signs.
With use of synthetic vision, the information of the pilot for
controlling the aircraft on the ground can be significantly
enhanced. This goal may be achieved by providing guidance
information based on a map representing the airport area \citep{mollersachs1994} 

TODO muokkaa tätä
The results demonstrated that an enhanced flight vision system may potentially enhance situation awareness and ameliorate problems witnessed when visibility drops requiring the use of LVO/SMGCS enhanced visual aids. However, the use of EV alone was not found to substantially enhance surface operations compared to baseline (i.e., no FLIR) without the addition of an AMM. Pilots consistently rated the AMM to be of significant value for these operations and, together, the EV and AMM was rated to be of tremendous benefit in maintaining SA and workload during 300 RVR approach and departures with simulated taxi-in and -out. The results also fully support the potential direction that EV with an AMM may provide an “operational credit” for SMGCS wherein an operator, with these requisite flight deck technologies, may be able to conduct lower than 500 RVR operations at airports that may only have a Level 1 LVO/SMGCS airport visual aids in place. Another option may be to enable under 1200 RVR surface operations at airports that do not have any LVO/SMGCS airport visual aids in place.
The FAA has stated that, “taxiing on the airport surface is the most hazardous phase of flight” (Gerold, 2001). Almost a decade later, that statement still rings true, but LVO/SMGCS enhanced visual aids and other controls are significantly improving this situation. Emerging flight deck technologies offer a potential means to create an equivalent level of safety and performance. These flight deck technologies, such as the E-SMGCS -AMM display and EV, could assist in fully realizing the potential of NextGen by offering a more affordable path toward safe and efficient LVO/SMGCS operations through an “equivalent visual” paradigm.\citep{prinzel2013}

The use of AMMs to enhance situation awareness has long been established. However, little research exists that
investigated their use under low visibility surface operations. To date, research has been limited to visibility
conditions greater than 700 RVR and without the enhanced visual aids required under LVO/SMGCS operations.
In this research, the AMM design was based on NASA “best practices” for AMMs, existing published standards,
and an AMM information priority survey. The survey was collected on twenty commercial pilots, experienced with
SMGCS and AMMs, based on established methods (Schveneveldt, et al., 2000; Yeh \& Chandra, 2003). The results
evinced that pilots desired the following SMGCS elements be depicted under low visibility surface operations: Geographic Position Markers (GPMs), clear route, stop bars, and hold lines. These additional informational elements are added to the AMM to create an E-SMGCS display concept.
The E-SMGCS concept is a display mode of the AMM that is invoked by the flight crews when known LVO/SMGCS conditions exists (i.e., under 1200 RVR). The AMM then shows specific LVO/SMGCS information elements based on information priority survey. The E-SMGCS mode retains all normal AMM functionality and also provides the pilots with specific symbology to enable the pilots to cognitively map task priority elements between the AMM, paper charts, and out-the-window visual cues.

Conclusion
The results demonstrated that an enhanced flight vision system may potentially enhance situation awareness and ameliorate problems witnessed when visibility drops requiring the use of LVO/SMGCS enhanced visual aids. However, the use of EV alone was not found to substantially enhance surface operations compared to baseline (i.e., no FLIR) without the addition of an AMM. Pilots consistently rated the AMM to be of significant value for these operations and, together, the EV and AMM was rated to be of tremendous benefit in maintaining SA and workload during 300 RVR approach and departures with simulated taxi-in and -out. The results also fully support the potential direction that EV with an AMM may provide an “operational credit” for SMGCS wherein an operator, with these requisite flight deck technologies, may be able to conduct lower than 500 RVR operations at airports that may only have a Level 1 LVO/SMGCS airport visual aids in place. Another option may be to enable under 1200 RVR surface operations at airports that do not have any LVO/SMGCS airport visual aids in place.
The FAA has stated that, “taxiing on the airport surface is the most hazardous phase of flight” (Gerold, 2001). Almost a decade later, that statement still rings true, but LVO/SMGCS enhanced visual aids and other controls are significantly improving this situation. Emerging flight deck technologies offer a potential means to create an equivalent level of safety and performance. These flight deck technologies, such as the E-SMGCS -AMM display and EV, could assist in fully realizing the potential of NextGen by offering a more affordable path toward safe and efficient LVO/SMGCS operations through an “equivalent visual” paradigm. \citep{prinzel2013}

The display concepts tested in this experiment – typical of current and future PF HUD and PNF-AD displays
– showed poor incursion detection functionality. Only one of the runway incursion scenarios was detected
through use of the cockpit displays. Therefore, requirements for display and sensor technology for runway
incursion detection should be developed which span the breadth of the problem, including human perception,
sensor design and detection theory, crew procedures, and crew interface issues. Current flight crews are not
familiar with using head-down displays on short final to check for incursions. The displays are not
Fusion of Synthetic and Enhanced Vision
11 - 22 RTO/HFM-141
necessarily optimized for this role. This role was not intentionally included in the pre-experiment crew
briefing. \citep{baileyym2007}

Taxi Performance
Advances in HUD technology have extended its use to taxi guidance. During taxiing,
pilots rely heavily on visual navigation aids on the airport surface outside the
cockpit. Helping pilots to taxi during times of low visibility could, therefore, increase
the safety and efficiency of surface movements. However, as pointed out by
M. Wiggins (personal communication, September 4, 2003), the effectiveness of usingHUDsfor
taxi guidance depends on the accuracy and reliability of the route path
programming. It would therefore be necessary to include safeguards to ensure that
pilots do not blindly follow HUDs for example, onto an inactive runway.
A number of studies assess how effectively HUDs provide taxi guidance
(Battiste, Downs, \& McCann, 1996; Jones, Quach, \& Young, 2001). In
low-visibility conditions, poor taxi performance is dangerous, increases fuel costs
to airlines, and affects passenger schedules. McCann, Andre, Begault, Foyle, and
Wenzel (1997) examined taxi performance when pilots were using T–NASA’s
“Scene-Linked” HUDs and 3–D moving maps. The HUDs substantially improved
taxi performance over performance seen with 3–D moving maps. \citep{crawford2006}

\chapter{Järjestelmien käyttöön liittyviä haasteita}

Tässä kappaleessa kerrotaan erilaisista ongelmista, joita järjestelmien käyttöönotossa on otettava huomioon.

\section{Järjestelmien käyttöönotto vanhoissa ja uusissa ohjaamoissa}

Tässä kerrotaan lähinnä teknisistä haasteita, joita voi esiintyä otettaessa järjestelmiä käyttöön vanhoissa sekä uusissa ohjaamoissa. Luonnollisesti uusissa ohjaamoissa voidaan ottaa SVS huomioon jo niitä suunniteltaessa.

The retrofit question concerns whether useful and effective synthetic vision displays
are usable in aircraft that have limited-size display spaces. Two experiments were
conducted to examine the efficacy of these displays and develop field-of-view and
terrain texture recommendations for design. The first experiment examined issues of
field of view and display size using an Asheville, North Carolina, synthetic vision database
and fixed-based simulator. The second experiment was conducted on the
NASA B-757 aircraft at Dallas/FortWorth International Airport and investigated the
efficacy of both head-down and head-up displays and generic and photorealistic terrain
texture. Both experiments confirmed the retrofit capability and that all sizes and
texturing methods were found to be viable candidates for synthetic vision displays.
These results, future directions, and implications for meeting national aeronautic
safety and capacity goals are discussed. \citep{prinzel2004}

Although the safety and economic advantages and payoff to pursuing SVS are
great, there are significant research challenges to be addressed before SVS can be
considered viable as a technological alternative. To provide a better definition of
the concept of operations (CONOPS) of synthetic vision technology for commercial
and business aircraft, a workshop resulting in a CONOPS document was held
at the NASA Langley Research Center (Williams et al., 2001). The focus of this
event was to obtain wide-ranging input from the aviation community on the benefits
and features that synthetic vision might incorporate. The outcome of the workshop
and subsequent activities has been the identification of numerous challenges
and research issues that need to be explored in developing SVS display concepts.
Many of these issues can be classified as human perceptual, such as display size
and field-of-view (FOV) issues.
The issue of display size is driven largely by the need for displays compatible in
size with current aircraft displays (the retrofit issue) and potential next-generation
larger display surfaces (forward fit issue). Because current aircraft have either
electromechanical instruments (e.g., 737–200) or small “glass” displays (e.g.,
757–200), there are concerns about the efficacy of these cockpits to support SVS
because of the physically smaller instrument spaces. One option to address the retrofit
issue would be to present SVS on a head-up display (HUD), and research
questions turn to how best to display synthetic terrain on a HUD that has limited
graphical capabilities. Another option is to simply remove the traditional instruments
and replace them with synthetic vision displays, and research issues then
turn to whether the space constraints will allow SVS presentations to be usable by the flight crew. Because these displays have a small unity geometric FOV, the scale
factor might need to be increased (i.e., minified) to allow more of the visual scene
to be presented to make the SVS display effective (e.g., Roscoe, 1948). The
wide-angle lens effect of increasing FOV, however, interacts with display size and
can lead to perceptual distortions as the minification factor (MF) is increased (e.g.,
virtual space effect; McGreevy \& Ellis, 1986). \citep{prinzel2004}

\section{Ohjaajan suorituskyky ja kognitiiviset haasteet}

Tässä kappaleessa kerrotaan niistä monista haasteista, joita suurimmilta osin HUD-näyttöjen käyttö ja automatisoitu tekniikka ohjaamossa voi aiheuttaa.

There are other perceptual issues concerning the content and type of information
in the pictorial scene that also need to be addressed. SVS display scenes can
be constructed from terrain elevation data and smoothed with generic terrain algorithms,
or they can be created by adding color and photo-realistic texture content
information from aerial photographs. A research question that needs to be
answered is which method provides the best information and SA gain to the pilot.
Are the additional data cost and computing requirements for photorealistic
terrain worthwhile in terms of enhancements to pilot performance and SA? \citep{prinzel2004}

Automated aids and decision support tools are rapidly becoming indispensable tools
in high-technology cockpits and are assuming increasing control of "cognitive" flight
tasks, such as calculating fuel-efficient routes, navigating, or detecting and diagnosing
system malfunctions and abnormalities. This study was designed to investigate
automation bias, a recently documented factor in the use of automated aids and
decision support systems. The term refers to omission and commission errors resulting
from the use of automated cues as a heuristic replacement for vigilant information
seeking and processing. Glass-cockpit pilots flew flight scenarios involving automation
events or opportunities for automation-related omission and commission errors.
Although experimentally manipulated accountability demands did not significantly
impact performance, post hoc analyses revealed that those pilots who reported an
internalized perception of "accountability" for their performance and strategies of
interaction with the automation were significantly more likely to double-check
automated functioning against other cues and less likely to commit errors than those
who did not share this perception. Pilots were also likely to erroneously "remember"
the presence of expected cues when describing their decision-making processes. \citep{mosier1998}

In the "glass cockpit," as well as in domains as diverse as medical diagnosis, nuclear
power plants, manufacturing and process control, and Air Traffic Control (ATC),
human decision-makers are being exposed to and are required to utilize automated
aids to perform their jobs and make decisions. As these and other environments
become more complex and data-intensive, the use of automated aids and decision
support tools is likely to become even more commonplace and critical to performance.
Aircraft flight management systems, for example, are designed not only to
keep the aircraft on course, but also to assume increasing control of cognitive flight
tasks, such as calculating fuel-efficient routes, navigating, or detecting and diagnosing
system malfunctions and abnormalities. An inescapable facet of these
automated aids is that they change the way pilots perform tasks and make decisions.
Most of the changes have proven to be beneficial. The advantages these systems
offer in terms of increased efficiency and data storage and manipulation, for
example, is self-evident-computers can assimilate more information and process
it faster than humans.
Other repercussions of automated aids, however, are less positive. Several
researchers have documented problems in the use of advanced automated systems
in aviation, including mode misunderstandings and mode errors, failures to understand
automation behavior, confusion or lack of awareness concerning what automated
systems are doing and why, and difficulty tracing the functioning or
reasoning processes of automated agents (e.g., Billings, 1996; Sarter \& Woods,
1993). Additionally, automated systems introduce opportunities for new decisionmaking
heuristics and associated biases. Automation bias, a recently documented
factor in the use of automated aids and decision support systems, refers to errors
resulting from the use of automated cues as a heuristic replacement for vigilant
information seeking and processing. This article describes research examining the
nature and implications of automation bias in the cockpit, its correlates, and possible
countermeasures. \citep{mosier1998}

Automation as Heuristic
The availability of automation and automated decision aids feeds into the general
human tendency to travel the road of least cognitive effort. Typically, people try to
engage in the least amount of cognitive work they can get away with (Fiske \&
Taylor, 1994), will prefer strategies that are easy to justify (and do not involve
analyzing relative weights or numerical computations) and will often utilize heuristics
(or cognitive shortcuts) to reduce effort and information load. To be successful,
heuristics must provide quick and simple ways of dealing with a great deal of
information and must be reasonably accurate most of the time (for reviews, see
Kahneman, Slovic, \& Tversky, 1982, and Fiske \& Taylor, 1994). Automated aids in high-tech environments, such as the aircraft cockpit, provide
decision makers with a new heuristic, or shortcut, for decision making and task
performance. These systems are, in fact, designed specifically to decrease human
workload by performing many cognitive tasks-including information synthesis,
system monitoring, diagnosis, planning, and prediction-in addition to controlling
the physical placement of the aircraft. However, the presence of automated cues
also diminishes the likelihood that decision makers will either make the cognitive
effort to seek other diagnostic information or process all available information in
cognitively complex ways. Parasuraman and Riley (1997) describe this tendency
toward overreliance as "automation misuse." In addition, automated cues increase
the probability that decision makers will cut off situation assessment prematurely
when prompted to take a course of action by a computer or automated aid. For
example, Layton, Smith, and McCoy (1994) examined pilot use of a graphical flight
planning tool and found that computer generation of a suggestion or recommendation
early in the course of problem evaluation significantly impacted decision
processes and biased pilots towards the computer's suggestion, even when the
computer's brittleness (e.g., in terms of an inadequate model of the "world")
resulted in a poor recommendation with potential adverse consequences.
To the extent that other available information besides automation is processed,
decision makers may show either assimilation or discounting biases. Other indicators
may be interpreted as being more consistent with the automated information
than they really are (assimilation), especially if other cues in the environment are
ambiguous (e.g., Darley \& Gross, 1983; Glick, Zion, \&Nelson, 1988). Conversely,
cues that are completely inconsistent with automated information may be discounted.
Additionally, confirmational biases lead information processors to overattend
to consistent information and ignore other data or to process new information
in a manner that confirms one's preexisting belief and avoids recognition of the
need for its revision (Hamilton, 1981; Wickens \& Flach, 1988). To the extent that
decision makers are prompted toward a particular problem or diagnosis when
automated aids bring it to their attention, other information is less likely to be used
to create a new impression or to modify the impression of the problem created by
the automation.
Because automated aids and decision support tools, when used correctly, are
extremely consistent and provide cues that are highly correlated with other information,
using them heuristically will generally be effective. Diagnoses are made
correctly, power plants function efficiently, and airplanes fly safely using automated
aids. However, indiscriminate use of these tools will result in errors, as would
indiscriminate use of any other heuristic; in some cases, indiscriminate use may
have the paradoxical effect of increasing errors rather than eliminating them. In
particular, inappropriate usage of automated systems in decision making and task
performance may result in automation bias, a term describing errors made when
human operators use automated cues as a heuristic replacement for vigilant infor-mation seeking and processing (Mosier \& Skitka, 1996). Two types of automationrelated
errors, omission errors and commission errors, are negative consequences
of this bias.
Automation omission errors result when decision makers do not take appropriate
action because they are not informed of an imminent problem or situation by
automated aids. For example, a China Airlines B747-SP, flying at 41,000 ft., lost
power in its \#4 engine. The autopilot, which was set for pitch guidance and altitude
hold, attempted to correct for the loss by holding the left wing down, masking the
approaching loss of control of the airplane. The crew did not realize that there was
a problem with the engine and took no action to deal with it. When the captain
disengaged the autopilot, the airplane rolled to the right, yawed, then entered a steep
descent in clouds. Extensive damage occurred during descent and recovery (NTSB
Report AAR-86-03, in Billings, 1996). Evidence of the tendency to make automation-
related omission errors has also been found in Aviation Safety Reporting
System reports, as discussed by Mosier, Skitka, and Korte (1994). In a nonrandom
sample of 166 events, they found that the most likely flight phase for omission
errors to occur was the cruise phase. In many of the incidents, the crews set up a
system (not always correctly) to perform a task and then trusted the system to do
it. Once the crews delegated a task to the automation, they did not check other cues
to catch inconsistencies or mistakes in task performance. The 1983 incident in
which a Korean Airlines B-747 was shot down by Soviet fighters included a similar
causal chain. In this case, the crew selected a magnetic heading and followed it
throughout the flight rather than coupling the navigational system's inertial reference
system to the autopilot. The flight did not follow its originally planned flight
path but rather maintained the selected heading until it was shot down. The crew
relied on automation that had been inappropriately set up, and they never checked
their progress manually, allowing the flight to stray well into Soviet airspace
("Analysis of flight data," 1993).
Automation commission errors are errors made when decision makers inappropriately
follow automated information or directives (e.g., when other information
in the environment contradicts or is inconsistent with the automated cue) that have
begun surfacing recently as by-products of automated systems. Some airlines, for
example, are dealing with automation-induced commission errors in pilots' responses
to an overly-sensitive warning system that often indicated a cargo compartment
fire when in fact there was none. Even though the presence or absence of
the fire was verifiable on other cockpit indicators, many pilots consistently followed
the warning directive and flooded their cargo bays with fire retardant.The implementation of automated aids in the aircraft cockpit, then, carries the
potential for possible adverse influence, in that the situation assessment process
may get short-circuited by automated cues; that is, operators may stop short at the
automated display or not double-check the operation of the automated system via
other available cues. If we are to anticipate and reduce automation bias in the
cockpit, we must discover what patterns of automation bias will be displayed by
flight crews in a flight situation and how these errors can be ameliorated. Questions
related to this are: What cognitive processes are activated when crews utilize
information from automated decision aids? Are there internal or individual variables
that affect susceptibility to or resistance against automation bias? What kinds
of interventions will be successful in ameliorating automation bias and eliminating
resultant errors?
A wide body of social psychological research has found that many cognitive biases
and resultant errors can be ameliorated by imposing predecisional accountability,
which sensitizes decision makers to the need to construct compelling justifications
for their choices and how they make them. Increasing accountability can successfully
mitigate decision-making biases such as primacy effects (Tetlock, 1983), the
fundamental attribution error (Tetlock, 1985), over-confidence effects (Tetlock \&
Kim, 1987), and the "sunk cost7' effect (Simonson \& Nye, 1992). Accountability
demands cause decision makers to employ more multidimensional, self-critical,
and vigilant information seeking, as well as more complex data processing; it has
also been shown to reduce cognitive "freezing" or premature closure on judgmental
problems (Kruglanski \& Freund, 1983) and to lead decision makers to employ more
consistent patterns of cue utilization (Hagafors \& Brehmer, 1983). In sum, accountability
increases vigilance in decision making and increases the tendency to use all
available information for situation assessment.
The extent to which these effects generalize to human performance situations
has only begun to be empirically explored. In a recent study intended to parallel
and serve as an analog to the present investigation, Skitka, Mosier, and Burdick
(1996) reported overall omission-commission error rates of approximately 55\% in
a sample of students performing a complex, low-fidelity flight task. In this study, the imposition of accountability demands significantly improved performance.
Specifically, making participants accountable--either for the accuracy of responses
or for overall performance-reduced omission and commission errors. Because
improved performance entailed the verification of automated information against
other cues, differences in performance could be directly traced to increased vigilance
and attention to dl available information. It was apparent, therefore, that
imposed accountability had the effect of making operators more likely to verify the
accuracy of automated information and less likely to rely heuristically on automated
cues.
The use of automated cues as a shortcut in decision making may result in
omission or commission errors (automation bias). The imposition of predecisional
accountability demands has been found to successfully ameliorate biased decision
making in several social psychological contexts, and it has recently been found to
increase vigilance and reduce automation-related errors for students in a low-fidelity
flight task. It is not clear, however, that these results would generalize to a
population of experienced pilots using automation in the cockpit. In this study,
investigations were extended to glass-cockpit pilots in a part-task flight environment,
We hypothesized that (a) the rate of occurrence of automation-related errors
among pilots would be comparable to that found with students, and (b) accountability
demands in the aircraft cockpit environment would promote more careful,
data-based decision-making strategies and increased vigilance in decision making,
making pilots less susceptible to automation bias and more likely to check all
relevant information before making decisions or taking actions. We examined
patterns of errors associated with automation bias and the relation between errors
and accountability, and we gathered preliminary information on cognitive processes
associated with this phenomenon.\citep{mosier1998}

Pilots regularly rely upon probabilistic information to evaluate what they cannot
access directly (Wickens \& Flach, 1988). In traditional aircraft, crewmembers are
trained and develop skills in situation assessment through the use of system and
environmental cues. Fuel gauges, engine indicators, weather forecasts, altimeters,
and other instruments provide cues with which the human operator can assess and
make decisions concerning the state of the aircraft and its surrounding environment.
In most situations, processing is facilitated by intercorrelations among cues (Wickens
\& Flach, 1988). Expert pilots exploit this intercorrelation in their cue search
and may perceive sets of correlated cues as a single perceptual chunk (Ebbeson\ \&
Konecni, 1980). They frequently use feature matching and pattern matching as
diagnostic strategies. Pilots know and look for patterns or combinations of cues
that are most ecologically valid, reliable, or relevant for diagnosing particular
situations, and they are able to incorporate contextual information to formulate a
workable action plan based on their assessment of these cues (e.g., Kaempf \& Klein,
1994).
When an automated aid is introduced, however, it disrupts the pattern of cue
utilization. Automated aids present new, powerful cues. These cues are readily
available, are widely believed to be accurate, and are a highly salient source of
information. The computational, system observation, and diagnostic capabilities of
automated aids are advertised as being superior to that of their human operators.
Additionally, the implementation of automated aids may be accompanied by
diminished access to other traditionally utilized cues. Research on the use of
probabilistic cues, such as those found in the aircraft cockpit, has demonstrated that
decision makers may focus on salient cues and ignore other critical but less obvious
information, especially under time pressure (Wickens \& Flach, 1988), and also that
the activation of one "most powerful" cue may be sufficient for people to confidently
generate a decision, particularly if time is short (Gigerenzer, Hoffrage, \&
Kleinbolting, 1991). In combination, these factors contribute to the perception that
automated aids do not provide "just another cue," but rather are more important,
more diagnostic, and more reliable than previously utilized, conventional information
sources. \citep{mosier1998}

Omission Error Events
Descriptive analyses revealed overall omission rates for flight-related events of
approximately 55\%,' as predicted, replicating the patterns exhibited by students in
the Skitka et al. (1996) analog study. The altitude load failure and the headingcapture failure, the two events arguably most critical to aircraft operation safety,
remained undetected by 44% and 48% of the participants respectively. The frequency
misload was undetected by 71% of pilot participants. Only three pilots
detected all three flight-related events; five pilots failed to detect any of the three
flight-related events. The tracking task automation failure, which was completely
irrelevant to flight functioning, was detected by all of the participants, with reaction
times ranging up to 4 min.
Contrary to predictions, the number of omission errors did not vary significantly
as a function of experimentally-manipulated accountability. Omission errors were
correlated with total flight hours, r(20) = .49, p < .05, and with years of flight
experience, r(20) = .46,p < .05, suggesting that increased experience decreased the
likelihood of catching the automation failures. To ascertain other underlying factors
discriminating participants who were more likely to verify automated tasks (and
thus catch errors) from those less likely to do so, pilots were classified according
to the number of omission errors they committed. Those who missed two or three
of three flight-related events were categorized as "high-bias" participants (n = 1 I),
and those who missed none or only one event were placed into the "low-bias" group
(n = 10). Analyses of variance were conducted using bias group as the independent
variable and responses on the debriefing questionnaire (1-7 scale) as dependent
variables.
Bias groups were statistically equivalent on items such as comfort with the
experiment, confidence in their strategies, and confidence in computers. Low-bias
participants, however, reported more nervousness, F(1, 19) = 7.08, p < .015, a
higher sense of being evaluated on their performance, F(1, 19) = 2.21, p < .001, a
higher sense of being evaluated on strategies in use of the automation, F(1, 19) =
9.63, p < ,006, and a stronger need to justify their interaction with the automation,
F(l, 19) = 6.24, p < .02. Results indicated that those subjects who felt more
accountable (whether they were in the accountable condition or not) were less likely
to make omission errors than those who did not feel as accountable for their
performance. Commission Errors
All of the pilots (N = 21) who experienced the false engine fire message did
ultimately shut down the engine. This was contrary to responses on the debriefing
questionnaire indicating that an EICAS message without other cues would not be
sufficient to diagnose "definitely a fire," and that it would be safer, in the presence
of only an EICAS message, to retard the throttle of the indicated engine and
complete the go-around procedure with the engine running rather than to shut down
the suspect engine. Further analyses of the debriefing questionnaires, however,
revealed that unanticipated factors may have entered into the shutdown decision.
As part of the debriefing process, pilots were asked which cues were present duringthe go-around at SFO. All of the pilots correctly remembered that an engine fire
EICAS message was present. Unexpectedly, however, 67% of them also "remembered"
at least one additional cue that was not actually present, and most of these
"remembered" more than one phantom indicator.' Additionally, the number of
phantom cues that pilots recalled was related to their strategy in handling the engine
shutdown. Specifically, the faster pilots initiated and completed the shutdown
process, the greater the number of indicators they recalled. Number of indicators
recalled accounted for approximately 20% of the variance in the speed of the
shutdown process, including bringing the engine fire checklist to the view screen,
hitting the engine stop switch, and pulling the engine fire handle, r = -.45, p < .05. \citep{mosier1998}

HUD
A head-up display (HUD) is a projection of symbology into the pilot’s forward field
of view that enables the pilot to monitor the instrumentation while, theoretically, also
viewing the external domain. Although the HUD has been shown to improve flight
performance, there are perceptual and cognitive issues that need to be addressed. This
article reviews selected literature that investigates these issues and the possible solutions
posed and identifies areas that remain in doubt.
A major review of head-up display (HUD) literature is timely and necessary as it
has been 10 years since HUDs have been closely examined as a whole
(Newman, 1995). Many airlines around the world now use HUDs. In some cases
their use for the most critical phase of flight, approach, and landing, is mandatory.
However, there are still issues that have been investigated but for which
tested solutions have not been provided. This article examines the perceptual
and cognitive issues associated with HUDs based on the studies that have been
performed to date. It also looks at the advantages and disadvantages of HUDs.
Finally, emerging issues and applications are identified in brief.
\citep{crawford2006}

Themajority ofHUDresearch in the last decade has dealt with perceptual and cognitive
issues. One of the main areas of interest is whether pilots can view theHUDand
the external scene concurrently. It would appear that this is not the case (for reasons
outlined in the sections that follow) and that pilots need to switch attention back and
forth between the HUD and the external scene. Attempts have been made to overcome
these problems by using new forms of technology, such as conformal
symbology. However, there is still debate regarding the effectiveness of these measures.
These issues are described in the following sections.
Misaccommodation
Misaccommodation of the eye occurs when the focus is drawn inward by something
close. This is considered to be a problem because it impairs pilots’ ability
to detect targets and to judge their distance and size (Weintraub \& Ensing,
1992). HUDs are collimated to appear at optical infinity to overcome the problem
of misaccommodation. Collimation is intended to put the HUD symbology
at the same optical depth as the external world, which in principle should assist
with accommodation and reduce the time necessary to refocus (Naish, 1964).
The effectiveness of collimation and whether HUDs should be collimated has
been extensively debated. This debate has been covered in previous reviews
(Newman, 1995; Weintraub \& Ensing, 1992). Given that no new studies have
addressed this issue in the past 10 years, we provide only a relatively brief summary
of the issues here.\citep{crawford2006}

A number of studies suggest that collimation does not pull the pilot’s focus outward
to optical infinity, or that collimated HUDs may even exacerbate
HEAD-UP DISPLAYS 3
Downloaded by [Jyvaskylan Yliopisto] at 07:02 22 December 2013
misaccommodation (Hull, Gill, \& Roscoe, 1982; Iavecchia, Iavecchia, \& Roscoe,
1988; Norman \& Ehrlich, 1986). Weintraub and Ensing (1992), on the other hand,
argued that the bulk of evidence suggests that collimated HUDs do pull the pilot’s
focus outward, even if it is not always to optical infinity. They argued that the earlier
results were an artefact of the optical quality of the HUD image and the external
scenes used in these studies. High-quality images, whether generated by the
HUD or from the external environment, draw focus outward. Iavecchia et al.
(1988) used a relatively poor-quality HUD image superimposed over a
high-quality image of terrain, causing focus to be drawn inward. In contrast,
Weintraub and Ensing (1992) argued that if the external image is of poor quality
(e.g., because of fog or rain) high-quality HUD images will actually pull the pilots’
focus outward, partially offsetting the tendency for the resting point of accommodation
to be closer than the objects in the external environment. Similar arguments
were made by Newman (1987), who argued on the basis of subjective experience
that HUDs give the pilot a clearer view when flying through rain. To our knowledge,
the question of whether collimated HUDs produce misaccommodation or
whether they reduce it has not been resolved.
Another issue of concern is whether the HUD combiner glass itself, including
its frame and lack of movement compared with the external world, are a source of
misaccommodation. These items may provide perceptual clues that the HUD is
closer than the outside scene (Larish \& Wickens, 1991; Roscoe, 1987). However,
the same is true of dirt, rain, and glare on the windshield (Weintraub, 1987). There
is currently no strong evidence available to assess whether the HUD combiner
glass significantly increases the risk of misaccommodation, over the risk posed by
the contaminated windscreen itself. \citep{crawford2006}

Intuitively, one might expect that HUDs would enhance a pilot’s ability to detect
events in the external world because the pilot does not have to switch attention
back and forth between an HDD and the external environment. However, there
is strong evidence to suggest that HUD symbology can capture a pilot’s attention,
and impair the pilot’s ability to detect events in the external environment.
This effect is referred to as cognitive tunneling. In the following sections, we
briefly examine the nature of attention, and review available studies that have
assessed the issue of cognitive tunneling and the reasons why it may occur.
Attention
Information processing is critically dependent on attention. Research has demonstrated
that, in general, people are much better at detecting events in the envi-
4 CRAWFORD AND NEAL
Downloaded by [Jyvaskylan Yliopisto] at 07:02 22 December 2013
ronment if their attention is focused on the area in which those events occur
(Wickens \& Hollands, 2000). However, attention is a resource with limited capacity.
Under some circumstances, a single task or aspect of the environment
will capture all of the individual’s attention. If the individual focuses attention in
this way then he or she will filter out unattended information and may not detect
task-critical information. In other situations, people can divide attention across
tasks or aspects of the environment. Factors that influence an individual’s ability
to divide attention include the nature of the tasks (e.g., whether the information
is perceived via visual or auditory channels, and encoded verbally or spatially),
and the nature of the display (Ververs \& Wickens, 1998).
Display features that encourage divided attention may inhibit people’s ability to
focus attention on specific aspects of the display and vice versa (Ververs \&
Wickens, 1998). For example, putting similar objects together may support divided
attention, but make it difficult to focus attention on one particular object
within the display. Similarly, an element of a domain that has dynamic properties,
such as motion, may capture attention and be so compelling that it consumes the
majority of the attentional resource, so that there is not sufficient attentional capacity
to view other visual elements concurrently. \citep{crawford2006}

Perceptual aspects of the visual field such as motion, color, and frame of reference
distinguish the HUD from the external world. For this reason, the HUD and
external world may not be processed or visually attended to at the same time. This
results in aspects of the unattended domain being perceived only after some delay.
If the HUD is the more salient of the two domains, these elements of the external
world, especially those that are unexpected, may be more difficult to detect
(McCann, Lynch, Foyle, \& Johnston, 1993; Moodi, 1995). For example McCann
et al. found that response times for events occurring within the domain to which
the pilot was currently attending were faster than response times to events that occurred
outside that domain. It was suggested that the HUD may act as an
attentional trap and that the ability to concentrate attention on the HUD was more
robust than the ability to concentrate attention on the outside world, interfering
with the ability to focus externally.
Detection of Expected and Unexpected Events
Most research addressing the effects of cognitive tunneling has focused on the
detection of unexpected events. An initial study comparing HUDs with HDDs
found that landings were more accurate using HUDs for commercial airline pilots
flying a fixed-based simulator. However, there was a longer response time
to an aircraft that was located on the duty runway that was being approached
(Fischer et al., 1980). A similar study was conducted by Weintraub, Haines, and
Randle (1985), who found, in the final trial of their study, that there was a runway
incursion that was only noted by 2 of the 8 participants. Naturally, this wascause for concern and many studies have subsequently addressed this issue and
the reasons behind it.
Larish and Wickens (1991) examined instrument-rated pilots’ ability to detect
expected and unexpected events on the flight display and in the external scene,
when using an HUD and an HDD. Both display formats contained the same instrumentation
and were collimated to optical infinity to ensure that any observed differences
could be attributed to display position. Many of the early HUD studies
had confounded instrumentation, collimation, and display position. Therefore it is
possible that the superior flight performance that had previously been observed
with HUDs could be attributable to the quality of instrumentation, or the fact that
the image was collimated, rather than the position of the image. The key outcome
measure was the response time to the detection of expected and unexpected events
in the external scene and on the display. General flight performance, in terms of
vertical and lateral tracking ability and speed and heading control, was also measured.
The results showed that pilots took longer to detect unexpected events in the
near and far domain when the HUD was used. On the other hand, the pilots did detect
expected events on their display more quickly when the HUD was used. Unlike
many earlier studies, there was no advantage for the HUD in terms of flight
performance. Larish and Wickens concluded that the advantages observed for
HUDs may be due to the symbology that is used, and the collimation of the image,
rather than the physical location (head up or head down) of the image.
A recent study conducted at Boeing’s Integrated Airplane Systems Laboratory
investigated attention switching between anHUDand the far domain, and anHDD
and the far domain (Hofer, Braune, Boucek, \& Pfaff, 2001). Twelve pilots flew
four takeoffs and four approach and landings in each of the HUD and HDD conditions,
resulting in 16 runs for each pilot. Each run included an expected event.
These were display events (a frozen instrument), scene events (truck or aircraft incursion),
or a combination of display and scene events. Six events per pilot (three
HUD and three HDD) were serious enough that an accident could result without an
appropriate response. The symbology set for the HUD in this study was reduced.
The intention was to ensure that there was no hindrance of event detection due to
symbology obstruction. Furthermore, the HUD and the far domain information
were presented at the same visual distance, reducing accommodation bias. The
workload was considered realistic, but not excessively high. The pilots were informed
that there would be an event during each run in either the symbology layer
or the outside scene to reduce learning effects and increase detection. The pilots
were not informed what the particular events would be. However even knowing
there would be an event, 36.5\% of the events were missed in the HUD condition
and 26\% in the HDD condition. Across all pilots, 9 out of 36 accident events were
missed in the HUD condition and these were all in the approach and landing phase.
None of the accident events were missed in the HDD condition. These differences
were statistically significant. \citep{crawford2006}

SA
Maintaining SA on flight decks is essential for safe flight. SA is lost if the pilot or
crewcannot answer any of these three questions: (a)WhereamI? (b)WhereamI going?
and (c)Whatwill I dowhenI get there? The extent to whichSAhas been lost depends
on howmany of these questions cannot be answered. At the elementary level,
SA deals with mainly cognitive factors associated with perception of stimuli and
their recall through memory. The first level of SAdeals with perception of situation
data, the second level of SA indicates the ability to comprehend the situation data,
and the third level deals with the ability to use the data in projection of future states.
For the purpose of flying instrument approaches in terrain-challenged areas, the
most relevant situation data incorporates spatial and geographic awareness. When
evaluating SA in a flight environment, pilots must remain aware of and concerned
with the spatial relation of the aircraft with the surrounding environment (Endsley,
1995). Although spatial and geographical awareness may be most relevant to flying
instrument approaches,SAcan also be assessed at the level of chronological awareness,
involving the crew’s understanding of the sequence of activities going on
around them at all times. SA is not necessarily acquired instantaneously, but is built
up over time. \citep{schnell2004}

A number of
warning systems currently available on modern aircraftwarn the crewwhen the aircraft
encounters a dangerous situation, yet one characteristic of SVIS displays is
their ability to provide information to avoid dangerous situations in a proactive
rather than a reactive manner. \citep{schnell2004}

Research suggests that the optimal configuration of displays, controls, and formats depends upon the intended
function of the system, the phase flight, and the role of the pilots16,17 involving a balance between:
Fusion of Synthetic and Enhanced Vision
RTO/HFM-141 11 - 3
• Understanding – how the design promotes the perception of the SV and EV information, the
comprehension of its meaning, and the projection of their status in the near future.18
• Workload – how the design minimizes the physical (e.g., use of controls, visual scanning) and mental
(e.g., amount of cognitive effort necessary to generate understanding) workload for effective use and
understanding of the information.  \citep{baileyym2007}

A key interconnection between the factors of understanding and workload is the concept of display clutter –
i.e., an excessive number and/or variety of color and symbols, that obscures essential information, or presents
distracting, disorganized and unnecessary information delaying visual detection.
Clutter warrants special consideration for EV/SV as the designer is intentionally increasing the volume of data
presented to the flight crew. For the HUD, in particular, FAA certification policy16 formalizes this conundrum
in that “clutter should be minimized” yet, “essential or critical (HUD) data must always be displayed” such as
that necessary for EFVS operational credit. Thus, task-critical or essential EV/SV imagery must be displayed
but the information must not excessively interfere with pilots’ ability to see the actual runway environment
through the display or impede their perception, understanding, and use of the information. Declutter control
in present EFVS implementations allow the pilots to selectively add or remove symbology or raster (i.e., SV
or EV) imagery, but declutter controls also introduce pilot workload during task- or time-critical situations
and raise the possibility that critical information might be inappropriately removed. \citep{baileyym2007}

A common method of combining SV/EV information is by use of an integrated single display format with
simultaneous presentation of unadulterated SV and EV content. By visual proximity, this method minimizes
the visual scan and cognitive effort in integrating the disparate information. Typically, “inset” displays of EV
information have been used to take advantage of the “unlimited” field-of-regard in SV information to
complement a limited field-of-regard EV sensor. Integration in this manner allows the user to retain
comparison of the separate sources for improved understanding. However, careful design of the integration
process must be made to prevent an unintended loss of understanding. Pilot-control of control of the inset
“opaqueness” by averaging or “alpha-blending” has not been found to be optimal.10 Image degradation of the
blended image was the primary factor.17,19 A pure pixel-averaging technique may create a situation where a
poor quality (low content) sensor image obscures good synthetic data without adding any valued to the image;
conversely, a good quality sensor image is obscured by uncorrelated synthetic data. More sophisticated
blending methods are available to minimize this problem,17 but pilot control introduces the costs of workload
for control, a higher potential for miss-setting of the controls, and the clutter primarily negates its utility.10
Display clutter can be mitigated by not displaying both EV and SV on the same display simultaneously using:
• Spatial separation – by locating SV and EV information on different displays. This process forces the
pilot to look across displays and mentally perform the information integration. This methodology has
been demonstrated under NASA flight test, wherein SV information was presented on a head-down
primary flight display, and EV information was presented on the HUD. The pilots transitioned to the
HUD at a specific height above the landing runway. This methodology was found to be acceptable
although not necessarily without improvements being desired. Sufficient information must be on the
HUD to restrict the need for the Pilot Flying (PF) to go “head-down” to acquire task critical
information; otherwise, HUD usage can create “a loss of situation awareness” and additional
workload from visual scanning. Designs utilizing visual momentum assist in the integration.19• Temporal separation – by displaying either SV or EV information on the same display, using
Fusion of Synthetic and Enhanced Vision
11 - 4 RTO/HFM-141
automatic or manual selection for which source is displayed. An automatic transition has been tested
and it felt “natural” to the pilot.20 Without retaining some elements of SV or EV display, however,
“visual momentum” and the complementary benefits of both EV and SV may not be lost.
Using a single display, image fusion can reduce clutter. Fusion, in this case, creates an image wherein the SV
and EV sources are consolidated to the extent that the sources are indistinguishable. The drawback is the loss
of understanding from source comparisons and contrasts. The specific fusion methodology significantly
affects the utility of the resultant display.17 Feature-level fusion methods generally enabled higher image
contrast while retaining the source information; however, it may also retain some undesirable noise content of
the sensor inputs. Registration of the two image sources is of paramount importance for fusion.
Another method of EV/SV fusion displays SV-derived information symbolically, using symbols, icons, and/or
perspective shapes for conformal overlay with EV imagery. For instance, SV-derived symbology, in the form
of runway outlines, with simulated EV imagery provided visual momentum yet didn’t create any perceptual
confusion even when flying with significant navigational errors inserted into the SV-derived guidance.21-22 \citep{baileyym2007}

EV imagery may provide an element of traffic detection above and beyond unaided natural vision, but several
factors must be considered to realize this capability. First, imaging sensors are not a panacea. Detection and
recognition is dependent upon the sensor resolution and its sensitivity to the environment and “target”, the
size and contrast of the obstacle/object against the image background, and the display resolution.6,30-31 Second,
if the PF display uses flight vector information, the flight path marker symbol and guidance symbol, if
Fusion of Synthetic and Enhanced Vision
RTO/HFM-141 11 - 5
provided, may obscure an object.16 Finally, the pilot-flying’s attention is primarily focused on the landing
task, and the PF may not have sufficient attentional resources for “unexpected” scenarios. This task has been
rated as “unacceptable” and resulted in unacceptable workload.9 \citep{baileyym2007}

While the pilot-flying is primarily focused on flying the aircraft, the pilot-not-flying (PNF) or pilotmonitoring
in a two-crew operation does have the primary responsible for monitoring and verifying flight path
performance, cross-checking guidance and raw data indicators, and identifying the visual runway environment
and clearing the landing area.31 Unfortunately, like the PF data, the use of EV/SV information by the PNF to
perform the navigation integrity, obstacle detection, and runway incursion detection is relatively mediocre.
The results, again, appear to be influenced by the EV/SV integration and display methods employed.
During low-visibility auto-landings10 where most included an “anomaly” consisting of SV database
misalignment, runway incursions, and uncharted obstacle, piloted evaluations showed that:
• Using an EV-only HUD, 57% of the obstacles were undetected and 50% of the runs with the database
misalignment went undetected. 38% of the runway incursions went undetected. Despite this
relatively poor performance, the pilots subjectively preferred the Head-up implementation.
• A Primary Flight Display (PFD) concept, showing SV with a pilot-controllable EV inset image,
exhibited the worst performance for anomaly detection. The PFD inset concept missed 100\% of the
uncharted obstacles - all leading to hazardous situations and a 33\% rate of missed detections for the
database misalignments. Detection of runway incursions showed a missed detection rate of 33%.
The poor performance and low-acceptance of the head-down EVS insert concept was attributed to the
clutter of the image, the small EV image size, and confusion between the SV/EV images.
• With EV-only shown on a HDD, all uncharted obstacles were successfully detected (but 20\% of runs
continued into hazardous conditions because the evaluation pilots (EPs) didn’t recognize the severity
of the threat) yet 33\% of the runs missed the misalignment. A missed detection rate of 22\% for
runway incursions was found. This concept was well liked for its large image size and minimal
display clutter, but disliked because of the workload in transitioning from head-down to head-up
flight.
Direct research into the effects of EV/SV usage on crew resource management and crew coordination, in a
two-place cockpit, has not been studied extensively. Crew coordination in an EVS approach operation was
the primary focus of one study,32 but sensor-unique (in this case, a millimeter wave radar) issues of
range/azimuth versus elevation/azimuth imagery presentations predominated the work. Anecdotal evidence
from a flight demonstration program suggests that “a centrally-located display of EVS imagery” may facilitate
CRM and training.33 \citep{baileyym2007}

The majority of flight crews verbally noted the presence of the 50 foot offset (15/24) and 75 foot offset
(22/24) during the approach. None of the pilots executed a go-around with this anomaly. Each performed a
lateral correction and landed near the runway centerline. Video analysis showed that navigation errors were
predominately noted by the PF (~85\%) when they noticed that the pitch/roll guidance symbol was leading
them to the left or right of the runway. One person (flying as the PNF) noted the non-zero localizer deviation
on the PFD presentation while tracking the path centerline.
The flight crews were not instructed on the course of action to take when confronted with a navigation error,
and the pilots had relatively little training and experience with the system. Despite this, the study showed that
lateral navigation errors were verbally acknowledged a significant percentage of time and, even when
unrecognized (i.e., not explicitly verbalized), all flight crews landed safely and accurately on the runway.
These results suggest that dissociations between raw data, sensor, and/or database presentation should be
easily recognized and managed by experienced pilots. Pilot training to recognize these discrepancies could
further improve operations in the event of this anomaly. \citep{baileyym2007}

The ability of the flight crew to handle a substantial navigational solution error was not impacted by the
display concepts. In all display concepts, the navigation error was detected or ignored. The pilots landed
safely. Further analyses are on-going to tease out statistical correlations.
The ability of the flight crew to handle a runway incursion was neither impacted nor significantly aided by the
display concepts tested. Although the increase in near-domain symbology information (runway outline) did
not degrade pilot response to the Fire Truck runway incursion event, there was also not an observed
enhancement in incursion detection as hypothesized for the FLIR. The display concepts and scenarios tested
in this experiment – typical of current and future PF HUD and PNF-AD displays - did not show adequate
incursion detection functionality. All but one of the runway incursion scenarios were detected without the use
Fusion of Synthetic and Enhanced Vision
11 - 24 RTO/HFM-141
of the cockpit displays. Sensor and display design must be tailored to this function and corresponding crew
procedures and interfaces developed to support RI detection.
Numerous suggested improvements have been identified and are being worked. For instance, the PNFs
strongly suggested that a declutter capability on the PNF-AD should be developed. Symbology on the PNFAD
was strongly preferred and rated highly, but the presence of symbology degraded the readability of the
raster, particularly of the runway and touchdown point. \citep{baileyym2007}

WORKLOAD
Anders (2001) conducted flight trials with airline pilots using the A330 Full Flight
Simulator at the University of Berlin. Anders found that the PFD is the most important
display and it draws increasingly more attention during approach and landing
from the time the airplane is in the clouds to the time the runway is visible. Anders
also found that the PFD was looked at or fixated about 40\% of the time as the
primary source of information during flight.Within the fixation, about 11\% of the
time was spent on saccades, during which no information is acquired. Thus, the
true percentage of fixation time is about 35\% on the PFD. The ND received a true
fixation percentage of about 18\% and all other true fixation percentages together
amounted to about 35\%. Most of the fixation time within the PFD was on the flight
parameters presented on the speed band, artificial horizon, and the altitude band. \citep{schnell2004}

A few studies have investigated whether changing the location of nonconformal
symbology alleviates the cognitive tunneling effect (Foyle, McCann, Sanford, \&
Schwirzke, 1993; Martin-Emerson \& Wickens, 1992). In an assessment of the
effect of positioning altitude information in three locations on the HUD, Foyle et
al. investigated ground path performance, altitude maintenance, and the concurrent
processing of the display and external scene. The results indicated that
when altitude and path information were superimposed, participants were unable
to attend to both the HUD and the outside world. Furthermore, when the altitude
information was over the path, there was a trade-off between altitude and path
performance, with an increase in altitude performance and a decrease in path
performance. Foyle et al. suggested that the results may have been due to attention
being focused on the altitude information and hence, the inefficient processing
of the path information. When the altitude information was placed higher up
in the HUD, away from the ground path, the trade-off was not apparent.
Foyle, Dowell, and Hooey (2001) found that when HUD altitude symbology
was placed at least 8 degrees above the external ground path, the cognitive tunneling reported
by Foyle et al. (1993) was eliminated. When the symbology was displaced
in this manner, ground path performance was unaffected. A subsequent
study carried out by Dowell, Foyle, Hooey, and Williams (2002) demonstrated
that moving the altitude information in this way not only eliminated cognitive
tunneling, but improved tracking performance and enhanced the processing of
the HUD symbology and the external scene. It was suggested when the
nonconformal altitude symbology was superimposed on the ground path, the
compellingness of the altimeter was responsible for the tunneling, regardless of
the relevance to the task. \citep{crawford2006}

A conformal display is defined as one “in which the symbols appear to overlie
the objects they represent” (Newman, 1995, p. 234). An example of conformal
symbology is shown in Figure 2. It is thought that by overlaying the images,
they can be viewed concurrently, thereby overcoming the cognitive tunneling effect
(Naish, 1964; Wickens, 1997).
A number of studies have shown that the use of conformal symbology produces
benefits such as a reduction in scanning (Martin-Emerson \& Wickens, 1993;
Ververs \& Wickens, 2000; Wickens \& Long, 1994). In addition, conformal displays
have been found to be less distracting and require less effort to attend to the
environment (Boston \& Braun, 1996). When investigating flight path tracking and
event detection, benefits of a conformal HUD were shown to be faster detection of
changes in symbology and traffic and an increase in flight path tracking accuracy(Fadden, Ververs, \& Wickens, 1998). However, when unexpected events were introduced,
the probability of detection was still degraded when using the HUD.
Wickens and Long (1995) examined flight performance and event detection using
conformal and nonconformal symbology sets in either anHUDor anHDDcondition.
The flight performance measures included flight path control and airspeed
tracking. Benefits for flight path control were found for the HUD condition when
conformal symbologywasused. These results suggest that the performance benefits
from HUDs stem not only from the reduction in scanning that is required when the
image is positioned head-up, but also from the use of conformal imagery. However,
a slower response to the unexpected event in the far domain occurred withHUDuse.
The cognitive tunneling effect was attenuated by the use of conformal imagery. The
authors cautioned against cluttering theHUDwith toomuchnonconformal imagery
as this may lead to slow detection rates for unexpected events. \citep{crawford2006}

Clutter and Intensity
It has been suggested that some of the benefits associated with the use of HUDs
may be canceled out by clutter (Ververs \& Wickens, 1996). Clutter is thought to
be one of the causes of cognitive tunneling and may interfere with the processing
of information in both the near and far domains. A number of incident reports
have highlighted the problem of clutter. For example, May and Wickens
(1995) described a military incident in which a pilot failed to detect a barrier on
a runway. It appears that the level of brightness of the HUD and the amount of
symbology led the pilot to fixate on the display and, hence, miss the barrier. In
the case of a similar incident, the United Kingdom’s Air Accidents Investigations
Branch (2000) concluded that the pilot of a Tornado that collided midair
with a Cessna 152 may not have seen the Cessna due to the clutter of the Tornado’s
HUD. It was reported that “it is possible that the effects of clutter in the
HUD reduced the probability of detection at a critical moment” (Air Accidents
Investigation Branch, 2000, pp. 4–5).
Some studies have shown that conformal displays can help reduce the effects of
clutter. For example, Boston and Braun (1996) found that in high-clutter situations,
a conformal display reduces the time it takes for a pilot to detect an obstacle
in the far domain.
Another way to decrease clutter may be to highlight salient information and reduce
the luminance of information that may be less important and distracting (May
\& Wickens, 1995). Ververs and Wickens (1996) found that an increase in contrast
ratio assisted pilots in cruise flight in responding faster to changes in heading, airspeed,
and altitude indicators in the HUD condition. Furthermore, when the contrast
ratio of the HUD was the same as that of the HDD, the detection of events in
both the near and far domain was superior in the HUD condition. Including additional
information in the display hindered event detection. Lowlighting the additional
information, however, provided pilots with a sense of what was important
on the display and distraction from far domain elements was less likely. The results
from this study suggest that putting symbology into an appropriate location
on the HUD, and ensuring an appropriate level of symbology intensity and contrast
with the environment, improve HUD performance. However, both of the
studies just described were conducted to reflect cruise flight and not the landing
phase. Therefore, these results may not generalize to other phases of flight.
In a study examining HUDs and HDDs, Wickens (1997) found that clutter effects
appeared to be mediated more by the number of elements than by the overlapping
of symbology on the far domain. Furthermore, the benefits of a reduction in
scanning in the HUD condition outweighed the costs of clutter, even though the
high-clutter displays did result in a delay in the detection of events in the near and
far domains. The poor detection of events with high clutter was found in both the
HUD and HDD conditions. \citep{crawford2006}

Workload
High workload seems to be associated with an increase in cognitive tunneling. If
cognitive tunneling is caused by limitations in attentional capacity, increasing
workload should further reduce a pilot’s available capacity, thereby exacerbating
the tunneling effect. However, there are very few studies comparing the workload
of HUD and HDD in the civilian domain. Although there have been some
recent studies investigating pilot workload while taxiing, high-fidelity investigations
into workload during commercial flight operations need to be conducted.
The results from military studies cannot easily be applied to the commercial aviation
sector because of the differing nature of equipment and flight situations.
For example, there are differences in currency and recency, the number of airport
movements, fatigue levels, and schedules. These factors are likely to confound
comparisons across the two sectors.
Some evidence to support the assumption that workload will exacerbate cognitive
tunneling was provided by Larish and Wickens (1991). Two levels of turbulence
(high and low) were used to vary the workload for instrument-rated
pilots in a flight simulator. The differences in response latency to unexpected
events between the HUD and HDD conditions were greater under high levels of
workload, suggesting that workload does increase cognitive tunneling. Interestingly,
the opposite effect was found for the detection of expected events. Pilots
using the HUD were faster at detecting expected events in the near domain than
pilots using HDD, and this difference was stronger under high-workload conditions.
The authors argued that in a high-workload situation, the HUD may induce
a narrowing of attention to avoid distraction from the superimposed
images, or a change to the pilot’s scan pattern, due to the superimposed images.
They concluded that dividing attention between the two overlapping sources is a
difficult and unnatural cognitive task that may exhaust resources in
high-workload situations (Larish \& Wickens, 1991).
Pilots, on the other hand, appear to believe that HUDs reduce their workload.
In the Boeing study described earlier, the pilots reported that the HUD reduced
their workload. Furthermore, the pilots reported that they found it easier to
switch attention from the HUD to the external scene, compared with the HDD,
and that the HUD was easier to use. The positive evaluations of the HUD provided
by the pilots occurred despite the fact that the HUD produced an increased
number of missed events. These results suggest that the cognitive tunneling effect
is counterintuitive, and that many pilots are not aware of its existence. Hofer
et al. (2001) concluded that “Pilots think they are seeing everything because all
the information is being presented in their visual field when in fact they are not
attending and processing everything” (p. 2). Additional studies into the effects
of workload on cognitive tunneling, and pilots’ awareness of these effects, need
to be carried out. \citep{crawford2006}

Spatial Disorientation and Unusual Attitude Recovery
The use of HUDs in instrument meteorological conditions has raised concerns
that they may contribute to spatial disorientation (Zenyuh, Reising, McClain,
Barbato, \& Hartsock, 1987). Barnette (1976) found that 30% of pilots reported
that the use of HUDs was associated with an increased risk of spatial disorientation
(see also Newman, 1980). Newman (2000) argued that this problem was
caused by the symbology used at the time. Because the early HUDs were designed
to be used as gun sights and not as a primary flight instrument, their
symbology may not have been adequate to support the pilot in instrument meteorological
conditions. This would be particularly important for recovery from
unusual attitudes. Changes to the symbology, including the use of a compression
pitch ladder, appear to have alleviated the problems (Newman, 2000).
Roscoe (1987) argued that the change in focus from the HUD to the external
world produces spatial disorientation. As pointed out by Newman (2000), none
of the studies conducted to date have supported this concern, although improvement
of some features would assist in unusual attitude recovery (see below).
Furthermore, Newman argued that the distance of the HUD would be at least
that of the conventional HDD, so the change in accommodation from the HUD
to the external world should not cause spatial disorientation. Newman concluded
that modern HUDs do not cause spatial disorientation and that their advantages
far outweigh any disadvantages.
There is potentially some difficulty in recognizing unusual attitude and then determining
the appropriate maneuver to recover when using an HUD (Newman,
2000; Zuschlag, 2001). Newman noted eight HUD characteristics that may produce
difficulty in interpreting orientation cues, which in turn makes unusual attitude
recovery difficult. Three of these characteristics (clutter, framing, and
accommodation traps) have all been mentioned previously in this article. The other
five are poor upright compared with inverted cues, digital data and rate information,
full-scale pitch angles, pitch ladder precession passing zenith or nadir, and
velocity vector control.
In the case of poor upright and inverted cues, traditional attitude indicators include
color to show sky and ground, which cannot be matched with today’s monochromatic
HUD design. Hence sky–ground discrimination may be difficult. When
airspeed and altitude are presented digitally, there may be difficulties in interpretation.
However, there is also concern that HDD analog formats such as tapes and
pointers may increase clutter on an HUD (Zuschlag, 2003).
Full-scale pitch angles make the symbols move very quickly across the pilot’s
field of view and therefore become hard to interpret. The compression of the pitch
scale will slow the movement of the symbology so it can be read and may also alert
the pilot to an unusual attitude (Newman, 1995). The precessing of the pitch ladder
to simulate an attitude director indicator avoiding gimbal lock (when the velocityvector passes 90dg nose up or down), is no longer a feature of HUDs. Finally, pilots
using the HUD velocity vector as a control parameter may have trouble during unusual
attitudes because they pull instead of push on the stick during high angle of
attack conditions.
The Federal Aviation Administration (FAA) of the United States suggested that
HUD designers should avoid confusion between input guidance and orientation
symbology. This is necessary if the HUD is intended to provide orientation only
during upsets or unusual attitudes. Cues must be designed to prevent them from
being mistaken as flight control input commands. For example, “a cue for left stick
input should not be confused with a cue indicating direction to the nearest horizon.
Guidance should be removed if cues become invalid at extreme attitudes, such as
zenith, nadir, or inverted” (FAA, 2001, p. 31).

Additional Areas of Research
There are a number of outstanding issues that require further research. For example,
there does not appear to have been any research conducted into the use of
vision aids and correction in pilots that may use HUDs. In addition, research is
warranted into the use of HUDs in single and multicrew environments; the effects
of pilot qualifications, training, and experience; and the training practices
and experience of operators.
Research is currently being conducted at the FAA/Volpe National Transportation
Safety Center to provide the FAA with guidelines for certifying HUDs for civilian
use (FAA, 2002). Twenty-two HUD design issues have been identified by
FAA experts while certifying HUDs. Further research is being conducted to determine
how pilot performance is affected by each of the design issues. The 22 issues
are broken down into the following categories: location and format design of flight
information, display effectiveness to support the intended task,HUDeffectiveness
in displaying and guiding recovery from unusual attitudes, consistency, and
discriminability ofHUDsymbology, and pilot physiological stress associated with
HUD optical design.
A further area of investigation might include HUDs and the proximity principle,
which is a principle of perception that was first identified by the Gestalt psychologists.
The central idea of this principle is that the smaller the gap between
stimuli, the more likely those stimuli are to be seen as belonging together. The gap
can be in terms of space or in terms of time. Although this principle has been investigated
by putting similar items together in the HUD visual field to ease processing,
the HUD could also break down the external field stimuli, making them hard
to interpret. Flight Lieutenant Robert Woodbury at RAAF Richmond demonstrated
this effect to the first author by showing a photographic image of an HUD
plus three lights visible in the external domain. It was not until the HUD was removed from the field of view that it was easy to see that the three lights were part of
a preceding aircraft. To our knowledge, no studies have investigated this issue. \citep{crawford2006}

However, there have been some problems that have arisen from the use of HUDs.
Prefaced by Fischer et al., a phenomenon known as cognitive tunneling has
continued to be cited by a number of studies as adversely affecting performance in
the detection of unexpected events (Larish \& Wickens, 1991; Wickens \& Long,
1995). Larish and Wickens found that, under particularly high-workload conditions,
the HUD induces a narrowing of attention to processing the routine information
on the symbology. They noted that pilots may have become fixated on the
symbology, thereby interrupting their scanning patterns for low-probability events,
in this case the appearance of a wind-shear alert.
Some concerns have also been raised regarding the symbology cluttering the
pilot's view of the world outside. Superimposing the instrumentation in the pilots'
forward field of view may make it difficult to search the environment for information
(Weintraub \& Ensing, 1992). For instance, studies have shown that pilots flying
with HUDs failed to notice or reacted less quickly to obstacles on the active runway
during an approach (Fischer et al., 1980; Wickens \&Long, 1995). An incident was
noted in a military report that excessive brightness combined with an overload of
symbology probably resulted in the fixation on the display and distraction of the
pilot. The conditions led the military pilot to fail to detect a barrier on a runway,
and the result was a mishap. In the final report, the presence of the HUD was named
as a contributing factor to the incident.
To resolve some of the inherent problems with the use of HUDs, one must
understand how attention is modulated between the symbology and the environment
beyond and how this modulation is in turn influenced by task and display
characteristics. The fundamental reason for incorporating HUDs onto aircraft is to
allow the pilot to scan the instruments without requiring attention to be reallocated
inside the cockpit. HUDs allow scanning the environment and scanning the
superimposed instrumentation to be a matter of dividing attention between these
two sources of information. The locus of focused attention is determined by the
location of the information needed to be referenced by the pilot. In an HUDequipped
aircraft, four categories of information source locations can be defined:
(a) the objects in the environment, such as a runway or another aircraft in the area;
(b) the superimposed instrumentation presented overlapping the actual environment,
which is intended to draw the pilot's attention outward; (c) superimposed
instrumentation in an area in space closer to the pilot, which regardless of the
designers' original intent does not draw attention outward and gets processed closer
to the pilots' resting dark-focus point than optical infinity (see Roscoe, 1987); and
(d) the traditional head-down instrumentation panel inside the cockpit. The distinction
between (b) and (c) is at present somewhat fuzzy because of difficulties
measuring attention in depth (Atchley, Krarner, \& Theeuwes, 1997) and becauseof uncertainty regarding the extent to which image properties, such as collimation
and symbology conformality, modulate attention along the depth axis. For these
reasons, it is important to establish where attention is located at any given phase of
flight in order to display information appropriately to the pilot. For instance, during
the cruise phase of flight, scanning the instrumentation and scanning for traffic are
of equal importance, and collocating the sources of information at optical infinity
should allow the pilot more easily to divide attention between the two sources. On
final approach with the runway in sight, in contrast, the pilot's attention should be
primarily located on the runway and not the instrumentation. Here, the pilot will
need to filter the excess information in order to land.
It might be gathered from the two scenarios described here that the presence of
an HUD may not always be beneficial to the pilot. The second scenario requires
the pilot to filter or ignore the symbology to satisfactorily complete the goal of
landing. The effects of the additional clutter suggest that the information might be
more appropriately presented on a head-down display (HDD). Thus, a principal
trade-off is revealed between the two types of displays. HUDs support scanning
the environment but produce clutter that can hinder the detection of unexpected
events, whereas HDDs relieve the forward field of view of clutter but increase the
,area needed to be scanned. However, the drawbacks of the HUD may be lessened
by modifying the information to make it less salient and distracting to the pilot. A
closer look at the effects of clutter reveals how the locus of attention can be
modulated by HUD design characteristics.
There have been a number of studies that have manipulated the presentation of
information on displays in order to investigate the effects of clutter on performance.
The general finding from both basic attention literature (Eriksen \& Eriksen, 1974;
Teichner \& Mocharnuk, 1979; Treisman \& Gelade, 1980) as well as the appliedaviation
domain (Martin-Emerson \& Wickens, 1993; McCann, Foyle, \& Johnston,
1993; Schons \& Wickens, 1993; Ward, Parkes, \& Lindsay, 1995; Wickens \&Long,
11995) is that the presence of visual information is disruptive if it is not a required
element to the task at hand. Ward et al. found significantly slower response times
to a leading car stopping abruptly when using an automobile HUD as compared to
driving without an HUD. Similarly, in a simulator study, Wickens and Long found
that the use of an HUD slowed responses to a widebody jet unexpectedly taxiing
onto the active runway when compared to using similar symbology presented in
head-down position. However, the picture being painted for HUDs need not be so
bleak. For example, although both Wickens and Long and Martin-Emerson and
Wickens (1997) found that even relevant HUD imagery could impose clutter, both
investigations also revealed that, when this imagery was rendered in a conformal
fashion so that it overlaid and fused with counterparts in the environment, its clutter
effects were reduced. Pmicular methods need to be determined for reducing the
negative impact that clultter has on the pilot processing the information. Additionally,
the appropriatenesS of the information on HUDs needs to be examined within the context of the current task of the pilot. For instance, given a particular phase of
flight, what information should be presented and how?
Although HUDs have been studied extensively, past investigations have not
examined the critical issues in all phases of flight, particularly the cruise phase. It
is during this phase of flight that it is important to scan the environment for traffic
(e.g., see and avoid) as well as monitor the instrumentation. This is especially true
for general aviation flying in which visual flight rules (VFR) conditions are
characteristic of flight, and air traffic control (ATC) does not have the firm
responsibility of maintaining traffic separation. Until recently, there have not been
any studies in the literature that evaluated the impact of HUDs on the detection of
airborne traffic in simulated VFR flight, a critical issue for general aviation (GA)
flight. The fundamental goal of the two experiments presented here is to understand
how clutter costs (vs. scan costs) influence event detection both on the symbology
and in the environment during the cruise phase of flight. Given that our interest is
in the effects of clutter as a potentially inhibitory phenomenon, we vary the amount
of information-presented to the pilot. A second issue concerns how the effects of
intensity and contrast may modulate the effects of clutter. We examine this issue
by manipulating the weather (background environment) against which the instrumentation
was displayed and the intensity of the symbology itself. Although the
two experiments are fundamentally similar in investigating flight-path tracking and
the detection of near and far domain events as display location, symbology intensity,
and weather conditions are varied in a cruise flight scenario, they also differed in
three key respects: (a) Experiment 1 is a low-fidelity simulation, and Experiment
2 is a high fidelity visual simulation; (b) Experiment 1 manipulates the image
conformality; and (c) Experiment 2 varies the amount of information presented on
the symbology \citep{ververs1998}

Repeated measures analyses of variance (ANOVAs) were used to analyze the data
in this experiment. Two precautionary measures were taken to provide an unbiased
examination of the results of this study. First, in an attempt to minimize the
possibility of Type I errors, a decision was made to usep < 0.01 as the criterion for
a significant effect instead of p < 0.05. We recognized the potential that this
adjustment would raise the possibility of committing Type I1 errors for any one
comparison (Loftus, 1996). However, this adjustment was made to avoid being
overly conservative (e.g., employing a Scheffi correction), which would have
further increased the chance of Type 11 errors given the number of comparisons that
needed to be made. More importantly, though, is the consideration of practical
significance, in which the obtained difference between two performance scores is
reliable and meaningful. Therefore, every comparison was considered for practical
significance, and only interpretations of interactions that had plausible explanations
were considered. Another efficient use of statistical analyses was the use of planned
comparisons whenever informative comparisons could be established a priori. The
second precautionary measure was the use of transformed data. After a preliminary
analysis of the data, the response times were found to be positively skewed.
Therefore, the raw data were transformed using a logarithmic transformation (loglo)
to normalize the distribution. The resulting data closely approximate a normal
distribution.
Results of Experiment 1 highlight the issues of visibility and contrast in
processing HUD information. Performance on nearly all aspects of flight was
sacrificed in the HUD location by the greatly reduced contrast ratios that resulted.
At the same time, the reduced scanning provided by the HUD location benefited
the pilot in monitoring and detection of other aircraft. This benefit did not appear
to be offset or neutralized by the clutter. In a sense, this is not surprising because
the contrast ratios were so close to 1.0 and thereby provided little clutter to the
scene.
Although the results of Experiment 1 do not provide strong support for the
benefit of HUDs, it should be noted that, when the combination of weather and
symbology intensity provided the most favorable HUD contrast ratio, the level of
flight performance was, in fact, statistically equivalent to that in the head-down
condition. One objective of Experiment 2 was to eliminate the confound between
location and contrast observed in Experiment 1. A second objective was to examine
in greater detail the role of clutter, and a third objective was to examine all of these
issues in a higher fidelity simulation. \citep{ververs1998}

Most prominent in the general conclusions is a clear advantage for the head-up over
the head-down location in the detection of events both on the symbology and in the
environment (see Figures 7 and 8). Three factors are probably responsible for the
emergence of the benefits here that were generally absent in Experiment 1. First,
the contrast ratios were equated and, hence, unconfounded between the head-down
and head-up locations. Thus, there was both a better contrast in the HUD condition
for processing the symbology and a reduced contrast in the head-down condition.
Second, the need for visual reaccommodation when processing information in the
head-down and head-up locations sequentially may have added to the response time
in the head-down condition. This difference was not apparent in Experiment 1, in which both of the images were presented at approximately three fourths of a meter
from the pilots. Third, of course, the location of the HUD provided the benefit of
reduced scanning. Thus, we cannot establish differential roles of reducing scan and
reaccommodation in producing the HUD benefit as Weintraub, Haines, and Randle
(1985) did, although Fadden and Wickens (1997), using a similar paradigm to that
employed here, provided data suggesting that both variables are important. However,
what is clear here is that the benefit from both of these factors outweighs the
clutter cost of the HUDs in detecting the traffic in the environment.
Clutter, however, did play a prominent role in slowing the detection of events.
The added information caused an increase in the visual search time for the detection
of other aircraft and disrupted the processing of the instrumentation in the highclutter
condition. This effect was equally detrimental to processing in both the
head-up and head-down locations. We failed to modulate the HUD clutter problems
by deintensifying some of the imagery through the design features of lowlighting.
Apparently, when the instrumentation is presented in the head-up location, all of
the symbology gets processed as a single element or group of elements, regardless
of the intensity of the individual elements. This findng was somewhat surprising
to us, so we returned to the data for further explication. Of relevance to understanding
the data is the modulation of the lowlighting effects by the location of the
instrumentation. Would lowlighting the instrumentation presented in the headdown
location produce different effects than when the instrumentation was presented
in the head-up location? In general, for the detection of symbology events,
location was of minimal importance in explaining the data. However, traffic
detection was affected differently depending on the location of the lowlighted
instrumentation. Although we found no advantage of lowlighting the task-irrelevant
information in the head-up location, the head-down location did show a marked
advantage for lowlighting when the task involved scanning the environment for
traffic (i.e., visual search). Comparison 1 la was no longer significant, indicating
that the lowlighted data did not interfere with processing, t(24) = 0.18, p > 0.10.
Also, comparison 1 lb became significant, indicating that lowlighting the task-irrelevant
information was effective in reducing the cost of the clutter interference
(by 0.39 sec) when the information is presented in the head-down location, t(24) =
2.54, p < .05. Evidently, when the task involves visual search and the information
needed to be accessed is head down, separating the task-relevant information from
the irrelevant information using lowlighting can be advantageous. In effect,
lowlighting made extracting the relevant information from the symbology less
effortful, thereby allowing more reserve attentional resources to be used for
environmental scanning (e.g., more head-up time). This finding is similar to those
of Martens and Wickens (1995), in which elements of a cluttered map display were
lowlighted to enhance divided and focused-attention tasks.
The fact that the effect of clutter was equivalent for head-up and head-down
locations speaks to the locus of its negative effect on human performance. Had clutter exerted a greater decrement for the head-up location, we would attribute the
negative effect to one of attentional focusing or information readout. Instead,
however, the equivalence of its effect in both locations suggests that clutter affects
visual search, or selective attention, an effect which appears to be of equivalent
magnitude whether the search space is compressed into a smaller area (HUD) or
expanded into the larger environment defined by both the forward view and the
head-down instrument panel (Wickens, 1992).
It is not entirely clear why the current results did not yield an HUD benefit for
tracking or flight path control along any of the three control axes. However, it may
be noted that the flight-path symbology used here was only partially conformal. A
compressed pitch ladder was used, and the horizon line was the only other guidance
information that directly overlaid its far-domain counterpart. Our past research with
HUDs with landing digplays has indicated consistent HUD benefits for tracking
only when conformal symbology is employed (Martin-Emerson \& Wickens, 1997;
Wickens \& Long, 1995), and even this effect is not universal (Fadden\& Wickens,
1997).
The data provided some insight bearing on the extent to which HUDs modulate
attention in depth. Our ability to examine this hypothesis was availed because of
lour fortuitous observation that the far-domain horizon (only visible in the clear
condition) provided a more accurate cue for lateral and vertical control than did the
HUD instruments alone (cloudy conditions) because of the greater lateral extent
and, therefore, higher gain of the "real" horizon. Considering data only in the HUD
condition, if attention was modulated in depth (Andersen \& Kramer, 1993), then
we would expect detection of events occurring in the environment to benefit when
the horizon was present in clear weather conditions. In addition, we would also
expect to see processing of the instrumentation to suffer a cost in the same
conditions, reflecting a trade-off of attention between domains along the same
head-up line of sight. However, these effects did not emerge. Although RT to
symbology events did rppear to be slightly (but not significantly) slower in clear
weather conditions, R\$ to the traffic showed the same trend, not the facilitation
predicted by the attenkion-in-depth hypothesis. Hence, rather than trading of
attention in depth, the current data speak more to a resource trade-off of attention
between tracking and detection tasks, independent of depth. Pilots invest more
resources in processing the more compelling horizon in the outside scene, attaining
better tracking perform\$nce as a result, but in the process marginally inhibiting the
task of monitoring for discrete events on the symbology and in the environment in
the head-down (near d~mainl)o cation. Such an interpretation certainly does not
disallow the possibility~o f attentional modulation in depth in this or other more
basic studies (Andersen\& Kramer, 1993; Downing \& Pinker, 1985; McCann et al.,
1993; Theeuwes, Atchlby, \& Kramer, in press). It only suggests that such effects
rnight have been dorniriated here by the overwhelming effect of vertical location
of the display. \citep{ververs1998}

The collective results of both experiments have shown that when ample contrast is
provided between the symbology and the background, the ability to track the control
axes is similar in the HUD and HDD locations. More importantly, it was found that
pilots were accessing information from the environment for attitude control. This
finding suggests an additional reason for pilots to have their vision directed in the
head-up location and outside the cockpit, when the horizon is available in clear
weather conditions.
Additional results indicated performance benefits for the HUD location for
target detection in cruise flight in both low-(Experiment 1) and high-fidelity
(Experiment 2) simulations. In Experiment 2, the head-up location facilitated
symbology event detection by 0.71 sec and aircraft detection by 0.66 sec. Consider
this time savings in the context of two aircraft both traveling at 250 kt and
converging. A 0.66 sec savings in detection time translates into an additional 560
ft (or 0.1 1 miles) to make an evasive maneuver. Furthermore, considering that pilots
need continually to scan between the instruments and the environment, the cumulative
time savings of presenting the instrumentation in the head-up location can
be substantial. It is important to note, however, that the current experiment did not
examine responses to truly surprising events-like the runway incursion on landing-
a circumstance that has produced the documented findings of HUD-induced
cognitive tunneling.
Poor contrast between the symbology and the background revealed problems
for the HUD in symbology event detection in Experiment 1. However, Experiment
2 overcame these problems by increasing the contrast ratio to expedite the response
time to detecting changes on the heading, airspeed, and altitude indicators in the
head-up position. The concept of lowlighting was introduced in Experiment 2 as a
method of display decluttering. Although there may be times when symbology
elements should be made less salient in order to direct and focus the attention of
pilots to critical display elements, Experiment 2 failed to reveal those benefits.
However, the benefits of Iowlighting certain elements did reveal a more rapid
detection of traffic when the instrumentation was presented in the head-down
location, presumably by increasing the efficiency of visual search for the relevant
information when it was presented head down.
The strength and significance of the results of these two experiments should be
considered for their contribution to the body of HUD literature as a whole. First, we
believe that the employment of licensed general aviation pilots added to the validity
of the overall results. Second, unlike many previously reported studies (e.g., Fischer
et al., 1980; Lauber et al., 1982), comparisons between the processing of the headdown
and the head-up symbology were made in which the format of the instrumentation
was consistent in both locations. Therefore, the conclusions drawn concerning
the benefits of HUDs were based on the location of the instrumentation in both the vertical and distance separation unconfounded by the differences in the symbology
set. Third, we believe the presentation of the instrumentation in the dynamic environment
of a closed-loop flight simulation was critical to the investigation of a pilot's
ability to process the information. This differs from some earlier work in which
conclusions were drawn from presenting static images to the pilots (e.g., Weintraub
et al., 1984,1985). Fourth, these studies investigated the use of HUDs in cruise flight,
a previously unexplored phase of flight by most HUD experimentation, which has
focused on the landing task. Fifth, for the first time in HUD research, the "see and
avoid" task was investigated using realistic midair targets for detection.
Finally, for the aviation community, HUDs are fast becoming commonplace in
the next generation cockpit (Proctor, 1997). Here is a word of caution. Experiment
2 revealed that clutter adversely affected detection of both commanded changes on
the instrumentation and aircraft in the environment. There is a definite need to
establish the essential elements with which to provide the pilot before display is
cluttered with task-irrelevant information. This study was limited to an experimental
scenario in the cruise phase of flight. Continued testing of HUD-related clutter
effects is advised befare HUDs can make a safe and smooth transition into the
general aviation cockpit. \citep{ververs1998}

Breakdowns in task management and task prioritization have been well documented
to contribute to mishaps in aviation (Chou, Madhavan, \& Funk, 1996; Funk, 1991).
Aclassic example here is the crash of an Eastern Airlines L1011 into the Everglades,
when pilots failed to manage their descending altitude while attending to an apparent
landing gear failure. Although such breakdowns have diverse psychological causes
(Dismukes, 2001; Dismukes\&Nowinski, 2007; Loukopoulos, Dismukes,\&Barshi,
2009), our specific interest in this article is focused on the phenomenon we label as a
collection of related phenomena known as attentional tunneling. We operationally
define this construct as, the allocation of attention to a particular channel of information,
diagnostic hypothesis, or task goal, for a duration that is longer than optimal,
given the expected cost of neglecting events on other channels, failing to consider
other hypotheses, or failing to perform other tasks. This concept is closely related to
what others have referred to as attentional fixation or cognitive tunneling (Prinzel,
2004; Regal, 2000; Stuart, McAnally, \& Meehan, 2001). In this regard, attention is assumed to be a commodity that can be either focused on a perceptual channel or a
cognitive representation or belief (Wickens \& McCarley, 2008). Often these two reinforce
each other, as when attention is focused on a perceptual cue or channel with
content that supports that particular belief.
The preceding definition must include both the forces that “lock the tunnel” to
its current channel, as well as a definition of a channel of neglect; that is, the channel
that is not attended to (but should be). Such a definition can account for more
specific mishaps in a wide variety of circumstances. For example, automobile accidents
while drivers are talking on their cell phone can be attributed to undesirable
“engagement” in the process of generating and understanding conversations (Horrey
\&Wickens, 2006; Strayer \& Drews, 2007; Strayer, Drews, \& Johnston, 2001).
Analysis of the Three Mile Island nuclear power accident associated the crisis, in
part, with operators’ excessive tunneling on one (incorrect) hypothesis as to the nature
of the obvious failure, and this hypothesis led them to fail to attend to contraindicating
visual cues (Rubenstein \& Mason, 1979). The Air Force has identified
attentional tunneling as being a major cause of F16 mishaps, and indeed a case can
be made that nearly all controlled flight into terrain (CFIT) accidents (Shappell \&
Wiegmann, 2003) can be associated with the inappropriate allocation of attention
away from important altitude-above-ground information.
Although salient mishap data clearly indicate that the tunneling problem exists,
such data often provide little usable evidence about its precise causes, because of
the invariable absence of control that such mishap data contain when they are used
retrospectively to infer causality (Woods, Johannesen, Cook,\&Sarter, 1994). This
is particularly true in very safe systems, such as aviation, where every accident appears
to be due to multiple causes (Reason, 1990). Thus a complementary approach
is to turn to more controlled flight simulation experimental data to reveal
both the prevalence of the attentional tunneling phenomenon in the general pilot
population and the causal factors that amplify the likelihood of tunneling. Although
such tunneling is known to be sometimes attributed to failure management,
as in Three Mile Island and the Everglades crash (Dismukes \& Nowinski, 2007),
and to guidance from automation (Mosier, Skitka, Heers,\&Burdick, 1998), we focus
later more specifically on display-induced attentional tunneling, with the emphasis
on aviation displays. We briefly review the evidence for head-up displays
(HUDs) in inducing such tunneling, and then integrate empirical evidence for the
contributing role of the highway in the sky (HITS) embedded within a synthetic vision
(SV) display suite, to attentional tunneling.
HUD-INDUCED TUNNELING
A now-classic flight simulation experiment by Fischer, Haines, and Price (1980)
set the stage for subsequent concerns about display-induced attentional tunneling. The authors observed that pilots flying with an HUD were less likely to detect an
unexpected runway incursion than those flying with conventional head-down instruments,
despite the fact that the HUD generally preserved the runway view
within foveal vision, where the incursion could be seen. The observation of
HUD-induced failure to detect an unexpected event was not based on a large
enough sample of pilots to reveal statistically reliable trends. However, the phenomenon
has been sufficiently replicated in both low-fidelity (Wickens \& Long,
1995) and higher fidelity (Fadden, Ververs, \& Wickens, 2001; Hofer, Braune,
Boucek, \& Pfaff, 2000) simulations to establish it as real, although it has not been
consistently observed in all studies (Kramer, Bailey,\&Prinzel, this issue; Lasswell
\&Wickens, 1995; Martin-Emerson \&Wickens, 1997). The existence of HUD-induced
attentional tunneling drawing attention “in” to the HUD imagery at the expense
of the far domain outside the aircraft has been established in a meta-analysis
of HUD studies (Fadden, Wickens, \& Ververs, 2000).
In considering the phenomenon of HUD-induced attentional tunneling, four caveats
must be highlighted. First, across all other performance measures (i.e., detection
of expected events both on the display and beyond, and routine flight control
or flight-technical error), HUDs are clearly superior to their head-down counterparts
(Fadden et al., 2000). Second, the costs only appear both when the event is
truly surprising and not very salient (Yeh, Merlo,Wickens,\&Brandenburg, 2003).
For example, Kramer and colleagues (this issue) only observed detection failures
on approach, for very small items (a baggage cart on the runway), not larger ones (a
fire truck). Third, although the tunneling effect results from viewing through a
cluttered HUD, it cannot be attributed directly only to a physical hiding of the
to-be-detected item. Fourth, this phenomenon appears to be mitigated, if not altogether
eliminated to the extent that the HUD image is conformal with, or “scenelinked”
to, the outside world imagery (Lasswell \&Wickens, 1995; Levy, Foyle, \&
McCann, 1998; Wickens \& Long, 1995). This suggests the possible role of attention,
assuming that the separate motion patterns of the nonconformal HUD imagery
and the outside world lead pilots to set up two attentional domains in depth,
such that focusing on one inhibits attention to the other (Krupenia, 2007).
In regards to the focus of this article, the implications of this research are thus
not that “HUDs are problematic” (a conclusion that has sometimes been unwarrantedly
drawn; Tufano, 1997), but rather that imposing an event or visual item
within foveal vision does not guarantee its detection, if it is unexpected and not salient.
This conclusion is now well documented by a strong program of more basic
research on inattentional blindness (Rensink, 2002; Simons \& Levin, 1998), some
of which has been extended into applied simulations in driving (Martens, 2007;
McCarley et al., 2004) and flying (Sarter, Mumaw, \& Wickens, 2007; Stelzer \&
Wickens, 2006), but is not reviewed here.
If such unexpected event detection is not guaranteed even within foveal vision
when attention is drawn to a different depth plane, one might expect detection to be further inhibited to the extent that visual attention is pulled away from the channel
hosting the event, toward compelling information in channels elsewhere in the visual
field. Indeed there is ample evidence for the declining performance of detecting
events outside of foveal vision, even when they are expected and task relevant,
so long as they occur against a reasonably cluttered display background, and are
imposed during periods of multitask workload (Nicolic, Orr, \& Sarter, 2004;
Stelzer \& Wickens, 2006; Wickens, Muthard, Alexander, Van Olffen, \& Podczerwinski,
2003). In the following, we consider the compellingness of 3D perspective
immersive displays as a possible cause of such tunneling. Here these displays
are represented by two advanced display concepts discussed in this special
issue: SV and the HITS display. 3D IMMERSION COMPELLINGNESS
We examine 3D compellingness, and its closely related concept of immersion as a
second example of the cause of attentional tunneling for two reasons. First, data
from other sources discussed later suggest that realistic 3D displays, particularly
with an “immersive” or viewer’s-eye perspective, tend to become an attention sink.
Second, two aspects of the technology addressed in this special issue, the SV depiction
and the HITS, with which SV is sometimes coupled (see Kramer et al., this
issue; Theunissen, Roefs, \& Etherington, 2009), present distinctly 3D perspective
images to the pilot, conveying, through relative size and motion cues, a sense of
depth and distance along the pilots’ line of sight, and thereby previewing future
hazards (SV) and four-dimensional (4D) flight path requirements (HITS).
Evidence for the compellingness of the 3D immersed display was provided by
Olmos, Wickens, and Chudy (2000), who compared display concepts for pilots’
hazard awareness, and found that a fully immersed 3D view of the forward flight
path, when coupled with a broader view display of the airspace below, led pilots to
neglect reporting targets in the broad viewdisplay, as their attentionwas seemingly
captured by the immersive 3D view. This neglect of the broad view was not shown
for the same targets when pilots flew with a 3D exocentric or 2D coplanar display,
hence pointing to the 3D immersive characteristics as responsible. Corresponding
evidence was obtained in a study of battlefield displays byWickens, Thomas, and
Young (2000). In addition, Yeh et al. (2003) observed that target cuing to a location
presented on an immersive head-mounted display led to attentional neglect of important,
but unexpected targets elsewhere in the visual field, in a manner that was
not observed when such cuing was presented in a less immersed form, or on a
head-down 2D display.
We can extrapolate from these findings to predict that, with the 3D SV and
HITS, presented head down, attentional tunneling would operate to engage pilots’
attention on these displays more than when situation and guidance information was presented at the same location, but in a less compelling format. Greater engagement
of attention here would lead to reduced attention allocation to the outside
world. Such a strategy would be problematic only to the extent that flight-relevant
information is present outside that is not present on the displays; that is, the
outside world hosts an off-nominal event (Foyle\&Hooey, 2003; Kramer et al., this
issue) analogous to the runway incursion studied with HUDs.
In a precursor to the SV studies we report here, Fadden et al. (2000) compared a
3D HITS display in a HUD location with a conventional HUD presenting instrument
landing system information in an approach and landing simulation. Although
they observed superior overall performance with the 3D HUD, they also observed
that the pathway induced a marginally significant 4-sec delay in pilots’ responses
to an unexpected runway incursion that occurred on a single (last) landing trial of
the experiment. Thus here the 3D display (here in a HUD rather than a head-down
location) led to more attentional tunneling than did the 2D display.
In the following, we integrate the results from seven different experiments that
have been carried out to compare SV and HITS technology with other less advanced
display concepts, all at a head-down location. These studies were generally
carried out to evaluate other aspects of performance such as flight path tracking or
situation awareness. However all had in common the occurrence of one or two totally
unexpected (off-nominal) events. The objective of this article is to examine
the collective results of all of these studies as they pertain specifically to the influence
of these display components on pilots’ responses to the unexpected event,
usually visible in a head-up outside location (Wickens, 2001). As with a metaanalysis,
the collective message of all of these is one that is not necessarily the
same as the individual message from any single study, because the latter typically
lack the statistical power to draw strong conclusions. \citep{wickens2009}

Other results of these studies are reported in detail in separate reports (see Table 1),
but the analysis here focuses strictly on the response to the off-nominal events.
When two such events were presented for a given pilot, for reasons explained later,
analysis only focused on the first of these.Within each scenario, flight path trajectories
were analyzed during the time period around the event, and categorized in
terms of whether clear avoidance maneuvers were or were not made (or, in case of
the runway displacement, whether or not landing proceeded on the incorrect trajectory
signaled by the SV runway). Because of the ambiguity in timing for those
pilots who did make an avoidance response, for most studies we were unable to establish
a precise time at which that response took place, enabling determination of
a response time. From these analyses, we were able to clearly classify those pilots
who missed the off-nominal hazard, and either flewthrough it, or flewdangerously
close, with no indication of an avoidance maneuver. Table 2 presents the aggregate
results of these miss-rate data across the seven experiments (SV4 is not included,
as this experiment did not include an off-nominal event; SV3 is represented three
times in the table because of different conditions in which pilots encountered the
off-nominal events). In three experiments (SV3, SV7, and SV8), some pilots flew
the off-nominal trial with the HITS, and others did not (using more conventional
navigational guidance instruments); here separate columns are provided for offnominal
detection rate.Asecond distinction within the table is between those studies
in which the off-nominal event was only visible in the outside world (top 7
entries) and those in which it was displayed on or near the SV display on the instrument
panel (bottom 2 entries). This contrast parallels the likelihood that the
off-nominal event will be near foveal vision when the eyes are focused on the SV
display.
The data reveal that, across all experiments, 71 out of 158 pilots, flying with the
HITS, failed to detect the off-nominal event, a substantial (45\%) minority. This
proportion is expanded considerably when the off-nominal event is only visible outside (67/130 = 52\%, compared to 4/28 = 14\% when visible on the head down
location), xpot2 = 21.9, p < .05. In contrast, for the smaller number of no-HITS conditions,
10 out of 36 (28\%) pilots failed to detect the event. This difference in proportions
between HITS (52\%) and no HITS (28\%) in detecting the off-nominal
out-the-window event is significant, xpot2 = 7.2, p < .05.
Three other features of the data help to account for some of the considerable
variance in miss rates across studies. First, we consider one study (SV1) with an
extremely high miss rate (16/18 = 89%), with the missed-approach blimp. In this
study, there was what could be classified as a double failure. That is, there was a
runway incursion (failure of the air traffic management system), for which the
HITS appropriately reconfigured itself to depict a missed-approach path. However
this was coupled with a failure of the display generator to note the midair blimp
following the missed approach path configuration (i.e., simulating a transponder
failure), so the path directed pilots to fly into the blimp. This rogue blimp can be
seen in the outside world of Figure 1a. Thus in the context of an emergency maneuver,
the pilot might be particularly vulnerable to attentional tunneling.
Second, in the only experiment yielding perfect detection, in which no pilots
missed the tower (SV3 at bottom of table),Wickens et al. (2004) employed a radio
tower that was visible on the SV display. Here all pilots appeared to detect the
tower adequately, as inferred from their flight path maneuvering. This result would suggest that excessive head-down time was responsible, in part, for failing to notice
the outsideworld event in the other studies when the off-nominal eventwas not
presented head down. Scanning data reported in other studies supported this conclusion.
In SV3, visual scanning was recorded for some of the pilots (Thomas \&
Wickens, 2004), and a comparison between those pilots who missed both the first
and second such off-nominal events, and those who detected both events, revealed
a stark difference in scanning strategy, with the former looking outside only 1% of
the time during the off-nominal trial and the latter scanning outside approximately
15% of the time. A corresponding scanning difference between detectors and
nondetectors (of suddenly dangerous weather visible outside) was also observed in
SV8, and was statistically significant (p < .01).
Third, it should be noted that presence of the off-nominal event on a display in
the head-down location is no guarantee that it will be detected. In SV7, this event, a
sudden change in the course of moving, violent weather near the runway, and visible
on the navigation display directly adjacent to the SV was, in fact, missed by 4
of the 20 pilots in the HITS condition, and 8 of the 20 pilots in the no HITS condition.
Failure to notice here was generally defined by the choice of a flight path that
led directly through the bad weather, rather than an alternative that did not. In this
experiment it is informative to note that the HITS led to less attentional tunneling
(although not significantly so) than the more conventional 2D navigational guidance,
a pattern opposite to that observed when the off-nominal event is only signaled
out the window. The authors attribute this reversal to the advantage of the
HITS in reducing workload, an advantage that offsets any attentional tunneling
cost, so long as the off-nominal event is located close to foveal vision. The analyses reported here set out to examine the extent to which two components
of advanced display technology addressed in this special issue—the SV and the
HITS displays presented in a head-down location—inhibited the noticing of unexpected
or off-nominal events in the outside world. The data fully suggested that
such inhibitionwas observed. Although a majority (58%) of pilots did successfully
detect (and evade or respond appropriately to) those hazards, a substantial minority
did not. Importantly, this failure to notice was much more linked to the HITS than
to the SV imagery. Indeed when the off-nominal information was only visible outside,
miss rate was 67 of 130 (52%) with the HITS, but only 2 of 16 (12.5%) when
the HITS was absent against the SV background.
This difference in response to the off-nominal event is important in two
respects. First, obviously it suggests that the greatest concern (and focus on mitigating
solutions) should lie with the HITS rather than with the SV display, an issue
we address later. Second, from a broader perspective of automation, according to a taxonomy of automation systems developed by Parasuraman, Sheridan, and
Wickens (2000), the SV system represents a class of Stage 2 automation systems,
designed to inform the user of the state of the world (e.g., an integrative status display).
In contrast, the HITS represents a class of Stage 3 automation systems, designed
to explicitly or implicitly advise a particular action (in this case a choice of
flight trajectories). Replicating prior research, we find that, although Stage 3 automation
works quite well (and often better than Stage 2) when it is operating correctly,
the consequences of failures in stage 3 operation are more severe (Crocoll\&
Coury, 1990; Sarter \& Schroeder, 2001).
Within the context of psychological research on change blindness and inattentional
blindness (McCarley et al., 2004; Rensink, 2002; Simons \& Levin,
1998; Stelzer \&Wickens, 2006), the failure to notice that we observed here can be
attributed to the combined influence of two factors: the low salience of the change
event (here the appearance of the hazard) and its low expectancy.We address each
of these causes in turn, as manifest in the current data. Salience and Visual Scanning
It is well established in both basic and applied studies that event salience (or
noticeability) declines both with changes in the physical properties of events (e.g.,
lower contrast ratios) and with greater eccentricity in peripheral vision (Stelzer \&
Wickens, 2006;Wickens et al., 2003;Wickens \& McCarley, 2008).We did not explicitly
manipulate physical salience, but the results clearly speak to the role of peripheral
vision in decreasing sensory salience. When we measured eyemovements
in SV3 and SV8, we found a close correspondence of increasing miss rate of outside-
world-only events, with increasing head-down scanning. Furthermore in SV3
overall, pilots tended to look out only around 10% of the time, while looking at the
SV display around 70% of the time. In SV8, these proportions were reported to be
approximately the same across all pilots, with significantly less outside world
scanning for the nondetectors than the detectors. Furthermore the tie between
heavy head-down scanning and the HITS display has been observed by others.
Williams (2002), for example, reported only 14% eyes-out time when pilots flew
with a HITS display, compared to 48% when flying with a baseline display.
The role of scanning (and therefore eccentricity in peripheral vision) in amplifying
the failure-to-notice effect is further established by examining data from the
two SV studies in which the off-nominal event was located head down, shown at
the bottom of Table 2. When it was located on a display adjacent to the SV HITS
display (SV7), it was missed on only 4 of 20 occasions; when it was directly present
on the SV display, it was not missed at all (SV2 with tower). (In this regard,
however, the HUD literature reminds us that even when looking directly at an
event, particularly through a cluttered nonconformal HUD, foveal vision is no
guarantee of detection when that event is unexpected and not salient.) The role of visual scanning and peripheral vision detection, and the fact that scanning
can be both explicitly taught (e.g., Fisher \& Pollatsek, 2007) and modified by
aviation expertise and experience (Bellenkes,Wickens,\&Kramer, 1997;Wickens et
al., 2008) brings to the fore two related aspects of the top-down, knowledge-driven
influences in accounting for the current findings. That is, (a) if pilots expected the
off-nominal events more, through training and experience, they would have better
detected them; and (b) such improved detection would have been mediated by an altered
scan pattern of less visual tunneling and more looking outside.
At least two aspects of the current data speak to this issue. In SV3 (Wickens et
al. 2004), the second failure that occurred was better detected than the first, and
scanning measures revealed more head-up scanning following this first failure (see
also Yeh et al., 2003), an experience-based modification of visual attention. The
better performance in detecting the second than the first off-nominal event was
also observed by Fadden et al. (2001). Thus, anchoring this finding within the
broader context of automation (Parasuraman, Molloy, \& Singh, 1993; Yeh et al.,
2003), pilots suffered from some degree of complacency throughout the several trials
in which automation functioned perfectly (i.e., depicting all hazards in the
airspace). Following the first failure, reflecting the fallibility of the full SV and
HITS automation system, their attentional strategy was more appropriately altered
(Moray, 2003), and detection of a second failure was not so disrupted.
There is a related possible explanation for the current findings, positing that the
novelty (and indeed infatuation) with the new technology might have been a cause
of excessive head-down engagement with the HITS display. This possibility cannot
be denied, and indeed it will be quite difficult to disentangle novelty-based engagement
from the effect of a heavy resource allocation into the HITS because of its very
real benefits in supporting accurate flight path tracking. Furthermore, it is the case
that, as the reliability of such automation systems in depicting all outside world hazards
increases (through improved database integrity assurance and blending SV with
enhanced vision [EV] imagery; see Korn, Schmerwitz, Lorenz, \& Döhler, 2009;
Kramer et al., this issue), the likelihood of such off-nominal events will be reduced.
However, in one of the most important ironies of automation discussed by Bainbridge
(1983), this reduction will mean that the periods of experience with perfect
automation will increase, thus rendering the pilot potentially even more vulnerable
to this “first complacency failure effect” (Molloy \& Parasuraman,1996).
Design and Training Implications
There are implications of these findings for both design and training, which well
associate themselves with the two contributing causes to attentional tunneling described
earlier, lack of salience and low expectancy, respectively. With regard to
design, it is clear that proximity of the display with the forward view will mitigate
(although might not eliminate) the problems of missing unexpected events visible in the latter. The intuitive obvious solution is to provide the HITS and the SV (or
EV) display on an HUD, a design consideration that is quite feasible (see Kramer
et al., this issue; Prinzel et al., 2004). Although the response to off-nominal events
visible through HUD versions of such displays have been examined (e.g. Kramer
et al., this issue), it appears that high-fidelity simulations have not compared their
detection through a HUD with their detection when the same immersive guidance
information is presented head down, or when less immersive guidance is presented
head up. Whereas very low-fidelity simulations (e.g., Wickens \& Long, 1995) suggest
that attentional tunneling through aHUDwill be attenuated when the imagery is
3D conformal, simulations of somewhat higher fidelity provide more ambiguous evidence.
In particular, the study by Fadden et al. (2001) offers a set of contrasts that
are informative. When presented head up (Experiment 1), detection of off-nominal
events was inhibited by the conformal imagery of a HITS in the air (noticing a runway
incursion), but was helped on the ground (noticing a taxiway blockage). When
only conformal displays were employed, detection of off-nominal events were inhibited
in an HUD relative to head-down location while in the air on approach, but
aided on the ground while on roll-out and taxi. Because of low statistical power,
none of these trends reached classical levels of statistical significance, but both contrasts
suggest that such attentional tunneling might be eliminated with conformal or
scene-linked symbology linking with the richer background texture of the ground to
create a single attentional object. This benefit is less obviously present in the air.
Hence the design guidelines to eliminate HITS and possibly SV imagery while on
approach below some critical altitude are probably wise, even as their restoration for
surface operations is also wise (Arthur et al., this issue).
With regard to training, current FAA recommendations as specified by Advisory
Circular 23–26 emphasize that pilots are to be wary of the compelling nature
of the SV displays, and stress their use only in conjunction with other flight and
navigational information. We simply go further here to emphasize that actual
hands-on training with such systems should include exposure to off-nominal
events (viewable only in a forward-view, outside-world location) to provide this
“first failure” experience in a safe ground location, where any complacency response
(or nonresponse) will not impose danger. That is, such training will more
appropriately calibrate expectancy once airborne flight with the new technology is
undertaken. Naturally, such training needs to reinforce the FAA guidelines for a
greater percentage of gaze to be head out than head down during visual meteorological
conditions. \citep{wickens2009}

Constraints and Limitations
This analysis, based as it is entirely on simulator studies, clearly has constraints
and limitations in its ability to generalize to understanding the causes and frequency
of attentional tunneling in real flight. The most obvious of these is the safety of the simulation environment. It could be argued that pilots flying an aircraft,
where lives are at risk, will be considerably more vigilant and careful in their
attention allocation strategies than those in the safety of a ground simulator. Although
this point might be valid, it is also the case that in some circumstances pilot
workload and stress in the aircraft could be much greater than they are in the typical
simulation studies, and given the well-established influence of stress on
attentional narrowing (Hockey, 1986; Wickens, 1996), such a factor could offset
safety-driven scanning.
A second obvious constraint concerns the level of pilot experience. All participants
in the current studies were general aviation pilots, and although some of the
flight instructors had great experience, none had prior experience flying with SV or
HITS displays. In contrast, a major target of generalization of these results is commercial
pilots, with training and certification on the systems, with a two-person crew
and hence with a second set of eyes to detect off-nominal events. It could be plausibly
asserted that these differences could mitigate attentional tunneling. We would
agree butwould also (a) endorse that such training needs to be coupled with effective
experiential off-nominal training as discussed earlier; and (b) note that ultimately
such systems might be destined for single-pilot general aviation operations.
Athird constraint concerns the nature of the off-nominal events themselves, and
the role of system integrity monitoring and other sensors, along with system redundancy
both within the flight deck, and between the flight deck and the ground.
These will likely lower the frequency of such off-nominal events considerably,
compared to their frequency in the current studies (i.e., in which they were 100%
likely to be encountered by a given pilot). Here again, we recognize such mitigating
effects, butwe reiterate correspondingly the irony of automation by which such
reduction will amplify, rather than mitigate, the “first failure effect” embodied here
by attentional tunneling (Bainbridge, 1983).
Collectively, these constraints point to the need for cautioning against the generalization
of simulation results to the air (just as is the case with any phenomenon).
However, the identification of the phenomenon in both mishaps, and in the
scaled up reality of reasonably high-fidelity simulation points to the need for researchers
to continually examine its manifestation in progressively higher fidelity
simulations and flight tests, as planners of the Next Generation Air Transportation
System have pointed out (Joint Planning and Development Office, 2007), and
hence it is gratifying to see this examination in two of the studies reported in this
special issue (Arthur et al., this issue; Kramer et al., this issue). \citep{wickens2009}

\chapter{SV- ja EV-järjestelmien tulevaisuus}

\section{Tulevaisuuden sovelluksia}

Tässä pohditaan, minkälainen tulevaisuus SV- ja EV-järjestelmiä mahdollisesti odottaa kaupallisen ilmailun näkökulmasta.

Based on our experimental data, it seems that SVIS displays such as our Condition
2 may find application in situations where the precision of aircraft navigation is of
utmost importance. Such situations could include commercial airline approaches
into terrain-challenged airports, where curved paths may be more effective in
maintaining maximum terrain separation than would be possible with conventional
approaches. Another application may be in situations where closely spaced
parallel approaches are conducted to parallel runways with minimal lateral separation. \citep{schnell2004}

The primary key to
providing SVIS for application in the real world seems to be a refined guidance
concept with a carefully tuned flight path predictor and a guidance cue that is tuned
to the predictive nature of the flight path predictor. The depiction of the terrain is
probably a secondary key point that adds to the usefulness of the SVIS. \citep{schnell2004}

EMERGING ISSUES AND APPLICATIONS
There is an abundance of new avionics available now and these are provided by
a multitude of manufacturers. For example, in 2002 Boeing conducted demonstrator
flights in a specially modified 737–900. The advanced avionics to be
evaluated by representatives from a variety of airlines included synthetic vision
system (SVS) displays; a head-up guidance system married to two infrared enhanced
vision systems (EVS); highway-in-the-sky navigational cues; a virtual-
traffic-cone surface guidance system; global positioning satellite (GPS)
landing system; and a software upgrade to the enhanced ground proximity warning
system (EGPWS). Other prevention technologies include NASA’s Runway
Incursion Prevention System, which alerts pilots on approach to other aircraft
that pose a threat. In the following sections, we consider the implications of
these types of emerging technologies for the use of HUDs.
Pathway HUDs
Pathway, tunnel, or highway-in-the-sky 3–D format flight path displays provide
a prediction and preview of a flight path. Although these displays have been in-vestigated for a few decades, combining the pathway display and HUD is a relatively
new concept.
Pathway HUDs have been investigated by Ververs and Wickens (1998) and
Fadden, Ververs, and Wickens (2000). The three elements that make up the new
HUD are a preview tunnel of where the aircraft will be in the future, a predictor
symbol, and a 3–D perspective. Preliminary tests with pilots showed positive performance
results, in the form of more precise tracking with lateral and vertical error
limited to approximately 10 ft. However, when an unexpected event arose for
pilots who were truly naive to the study (in this case a runway incursion), the event
was detected more slowly in the HUD condition than in the HDD condition. It
should be noted that this finding was not statistically significant, possibly due to
the insufficient power of the study. Nevertheless, the results are consistent with the
cognitive tunneling effects reported previously, without pathway displays. \citep{crawford2006}



\section{NextGen ja EVO-konseptit}

Tässä osiossa kerrotaan NextGen-ilmailukonseptista sekä EVO-konseptista sekä näönparannusjärjestelmän vaatimuksista, joita näihin konsepteihin on visioitu.

Tämä saattaa olla hyvä laittaa edellisen osion alle (tai sitten ei), katsottava muotoiluvaiheessa.

NASA is striving to develop the technologies and knowledge to enable EVO and to extend EVO towards a “Better-Than-Visual” operational concept. This operational concept envisions an "equivalent visual" paradigm where an electronic means provides sufficient visual references of the external world and other required flight references on flight deck displays that enable Visual Flight Rules (VFR)-like operational tempos while maintaining and improving safety of VFR while using VFR-like procedures in all-weather conditions.\citep{prinzel2013}

Taken together, the conclusions that can be drawn from these experiments are that
synthetic vision can be implemented on retrofit sizes and, therefore, can successfully
be introduced into the current aircraft fleet. To be effective, synthetic vision
presented on small display sizes would have to be minified and our results indicate
that the MF should not exceed 4.5 for optimal performance, although more research
is needed to confirm such a conclusion.
Because no performance differences were found between photo-realistic and
generic terrain texture methods, the generic terrain presentation might represent an
effective and lower cost option for synthetic vision displays, although photo-realistic
terrain does have properties that can increase the margin for safety and operations.
Several pilots did comment that photo-realistic texture would be helpful for
SA during climb, en route, and descent phases of flight. A recent flight test in the
terrain-challenged area of Eagle-Vail, CO, however, found no performance or SA
penalties for the generic texture concept, although pilots reported an overall preference
for the photo-realistic presentation (Bailey et al., 2002; Prinzel et al., 2002).
The NASA Aviation Safety Program is currently evaluating a synthetic vision concept
that combines generic and photo-realistic terrain texture to take advantage of
the benefits both methods offer for SA. \citep{prinzel2004}

The problem of reduced visibility challenges aviation goals to reduce the accident
rate and improve operational capacity (Federal Aviation Administration, 2001;
NASA, 2001). The approach of synthetic vision is to solve the problem through the
presentation of how the outside world would look to the pilot if vision were not restricted.
TAWSare steps in the right direction and they have significantly improved
safety, but the solution treats the symptoms and not the cause (Moroze \& Snow,
1999). Synthetic vision instead provides for proactive prevention of visibility-induced
accidents while also increasing the capability to make approaches in
weather conditions and airports not currently legal for low-visibility operations.
Although our research did not specifically address these aviation safety and operational
benefits, subsequent studies (e.g., Prinzel et al., 2002) have substantiated the
performance and SA enhancements of synthetic vision even while making complex,
circling approaches under conditions that are beyond current cockpit technology
capabilities. Furthermore, the concept described here represents only the
database and display concepts and not the total SVS, which will include synthetic
vision navigation displays; runway incursion prevention technology; database integrity
monitoring equipment; enhanced vision sensors; taxi navigation displays;
and advanced communication, navigation, and surveillance technologies
(McCann et al., 1998; Timmerman, 2001; Uijt de Haag, Young, Sayre, Campbell,
\&Vadlamani, 2002;Williams et al., 2001; Young \& Jones, 2001). These technologies
represent a comprehensive solution that will be evaluated in near-term NASA
simulation and flight research. Together, synthetic vision may considerably help
meet national aeronautic goals to “reduce the fatal accident rate by a factor of 5”
and to “double the capacity of the aviation system,” both with 10 years (NASA,
2001, p. 2). \citep{prinzel2004}


\chapter{Yhteenveto}

Synthetic vision has the potential to provide significant safety and economic benefits,
particularly if the system is effective as both a retrofit and forward-fit solution
to visibility-restricted problems. Previous research has shown the efficacy of synthetic
vision on large-size displays and, therefore, synthetic vision is expected to
be capable of effective presentation as glass displays become larger with each generation
of aircraft. Because the majority of the current commercial aircraft fleet has
electromechanical instruments or limited glass real estate, however, any significant
benefits would require answering the retrofit question of whether effective
presentation of synthetic vision can also be made in current aircraft cockpits.
Display Size
The retrofit question concerns our hypothesis that the HUD and smaller SVS display
sizes would provide adequate information to enable the pilot to make safe and
precise approaches. The results of the experiments confirmed the hypothesis and
suggest that SVS is viable as a retrofit candidate. Experiment 1 showed no differences
in path performance between display sizes or FOV, and Experiment 2
showed differences only for the HUD concept for lateral path performance. \citep{prinzel2004}

Analysis results indicate that the SVIS is superior to the conventional displays
for the majority of the measures that were obtained in the experiments.
Based on the results of the experiments, we feel that the SVIS is a display format
that improves the performance of pilots in many ways. \citep{schnell2004}

In summary, research suggests that there are a number of advantages in using
HUDs. These include increases in flight path tracking accuracy, except during
cruise flight; benefits for event detection, except in the approach and landing
phase and for unexpected events; lower visibility takeoff and landing; more accurate
approach and landing; the elimination of head-down time; a reduction in
the time taken to refocus between instruments and the external scene; and the
potential to use overlaid symbology for the external scene when it is not visible,
hence enhancing situation awareness. The major disadvantages of HUDs are difficulties
in switching attention between the internal and external scene and difficulties
in detecting unexpected events. Despite this, there is currently no evidence
to suggest that the use of HUDs is associated with an increased risk of
accidents.
Withthe use ofHUDsincreasing throughoutcommercialaviation,moreresearch
is needed to identify ways to address the issues just noted. From a practical perspective,
one of the most pressing issues concerns training.Wedo not yet know whether
it is possible to train pilots to overcome the effects of cognitive tunneling, or how
muchtraining would be needed if itwaspossible to do so.Oneoption is to train pilots
to scan more effectively by teaching them to take their attention away from theHUD
and into the far domain (Wickens, Helleberg, Goh, Xu,\&Horrey, 2001). We could
16 CRAWFORD AND NEAL
Downloaded by [Jyvaskylan Yliopisto] at 07:02 22 December 2013
not find any studies in the public domain that have addressed this issue. Other issues
that need to be examined include the use of HUDs in multicrew operations, and the
effects of fatigue and experience on performance when using an HUD. Although
HUDsoffer significant benefits to airlines in both productivity and safety, an extensive
program of research is needed to ensure that these gains are realized. \citep{crawford2006}

Results of this study suggest that automation bias is a significant factor in pilot
interaction with automated aids, and that pilots are not utilizing all available
information when performing tasks and making decisions in conjunction with
automation. Pilots exhibited the same overall rate of automation-related errors as
the student population in the Skitka et al. (1996) study, demonstrating that expertise
does not insulate individuals from automation bias. In fact, experience and expertise,
which might be predicted to make pilots more vigilant and less susceptible to
automation bias, were related to a greater tendency to use only automated cues. One
possible explanation for this may be that, because automated systems tend to be
highly reliable, more experience with them reinforces the notion that other cues are
merely redundant and unnecessary. Additionally, the higher-experienced pilots in
this study tended to be those more senior within their airline, and were currently
flying as captains. They may be used to delegating the cross-checking role to their
first officers rather than doing it themselves.
Although this study does not provide evidence that externally imposed accountability
affects the decision-making behavior of professional pilots, it does demonstrate
that the internalization of "accountability" for performance and strategies in
the use of automated systems impacts automation bias. Perceived accountability
was positively correlated with increased verification of automated functioning and
fewer omission errors. In other words, pilots who reported a higher internalized
sense of accountability for their interactions with automation verified correct
automation functioning more often and committed fewer errors than other pilots.
These results suggest that the sense that one is accountable for one's interaction
with automation encourages vigilance, proactive strategies, and the use of all
information in interactions with automated systems. The fact that the perception of accountability was not correspondent with our external manipulation indicates the
need to establish the degree to which accountability is a variable that can be
significantly influenced in pilots and other professional decision makers, who are
already functioning at a high level of personal responsibility for their conduct.
Alternatively, the lack of experimentally determined accountability effects could
be the artifact of a small sample, or the experimental manipulation could have been
confounded by a sense of accountability induced by the experience of participating
in a NASA study. The perception of accountability might also be part of some innate
cognitive style or personality construct, a hypothesis that will be addressed in a
future study.
Several aspects of the experimental tasks seemed to affect the tendency of
participants to verify the functioning of the automation; these included task importance,
predictability, and feedback. Descriptive data suggested that pilots were more
likely to catch automation events that involved altitude and heading than one that
involved a frequency error, corresponding with the typical ordering of flight
priorities as (a) aviate, (b) navigate, (c) communicate. The fact that the tracking
task automation failure so readily captured pilot attention can be explained in part
by the fact that the task display offered trend information (e.g., pilots could see
when the cursor was starting to drift out of the target area), as well as immediate
salient feedback on errors. In many real-world automation-aided tasks, pilots do
not receive either predictive information or immediate feedback on accuracy and
errors. Incorporating these features in the design of new automated systems may
be a way to facilitate vigilant use and aid in the detection of automation failures.
The finding that all pilots responded to the false engine fire event by shutting
down the indicated engine was unanticipated. Even more surprising was the fact
that their actions were contrary to responses on the debriefing questionnaires
indicating that some combination of cues would be necessary to diagnose "definitely
a fire," and that it would be safer, in the presence of only an EICAS message,
to retard the throttle of the indicated engine rather than shutting it down. Apparently,
these pilots were acting contrary to their self-described strategies. Part of the
explanation for their actions may rest in the "false memory7' data.
Pilots were definitely aware of the cues typically associated with an engine fire
and, in this time-pressured and cognitively demanding situation, were evidently
remembering a pattern of cues that was consistent with what should have been
present during the event. Real correlations among the cues--during an engine fire,
all of them should have been present--contributed to the illusion of their presence.
In similar situations during their careers (i.e., engine fire situations calling for the
shutdown of an engine), the pilots in this study would have been wrong if they had
not remembered the presence of several cues3 The more quickly they acted, the more "sure" they had to be that their actions were correct, and the more phantom
cues they remembered as having prompted their actions. Their judgments and their
memories were biased in the direction of confirming their expectations, and, as
Hamilton (1981) aptly remarked concerning correlated cues and expectations,
"[they] wouldn't have seen it if [they] hadn't believed it" (p. 137).
It is possible that this false memory phenomenon may be an additional mechanism
by which automation bias is bolstered. Pilots may not ever be aware that they
are using automated information as a short cut, either because the automated cues
are in fact consistent with other information (and no error results), or because errors
are not traced back to a failure to cross-check automated cues. In the false engine
fire event, for example, most pilots believed they had acted based on several cues,
and thus would not be prompted to change their strategies in the use of automated
information. Consistent with this analysis, pilots tended to falsely remember cues
that fit into their expectations but were not physically handled during the engine
shutdown. For example, they were less likely to remember the presence of an
illuminated fire handle (n = 2), which they had to manually press during engine
shutdown (and would have been forced to observe directly) than a master warning
light (n = 8), which was not directly manipulated as part of the shutdown procedure.
Explicit manipulation of a control made it more salient, and less likely to be
incorrectly remembered. \citep{mosier1998}

CONCLUSIONS
In conclusion, this study has documented the existence of attentional tunneling as a
legitimate concern for the SV display when coupled with the HITS. Such concern certainly does not fully compromise the very real benefits of the HITS in supporting
low-workload trajectory guidance, and particularly of the substantial benefits of the
SV terrain representation for supporting terrain awareness. It does, however, point to
the importance of attentional training for pilots who use this new technology. \citep{wickens2009}

%Lähdeluettelo

\begin{thebibliography}{}

% Hakasulkeisiin tulee kirjoittajien sukunimet (siinä muodossa kuin
% ne halutaan lähdeviittaukseen) ja julkaisun vuosiluku suluissa.
% Huom: Älä laita välilyöntiä ennen vuosiluvun alkusulkua.

% Normaali viittaus ym.-sanalla, ensimmäisessä viittauksessa kaikki nimet:

\bibitem[Bailey ym. (2007)Bailey, Randall E. , Kramer, Lynda J. \& Prinzel, Lawrence, III]{baileyym2007}
Bailey, Randall E. , Kramer, Lynda J. \& Prinzel, Lawrence, III 2007.
\textit{Fusion of Synthetic and Enhanced Vision for All-Weather Commercial Aviation Operations}.
NASA Technical Reports Server (NTRS), huhtikuu 2007.

\bibitem[Beier \& Gemperlein(1994)Beier \& Gemperlein]{beiergemperlein2004}
Beier, Kurt \& Gemperlein, Hans 2004.
\textit{Simulation of Infrared Detection Range at Fog Conditions for Enhanced Vision Systems in Civil Aviation}.
Aerospace Science and Technology, 8, s.~63--71.

\bibitem[Crawford \& Neal(2006)Crawford, Jennifer \& Neal, Andrew]{crawford2006}
Crawford, Jennifer \& Neal, Andrew 2006.
\textit{A Review of the Perceptual and Cognitive Issues Associated With the Use of Head-Up Displays in Commercial Aviation}
The International Journal of Aviation Psychology, 16:1, s.~1--19.

\bibitem[Hooey \& Foyle(2007)Hooey, B.L. \& Foyle, D.C.]{hooey2007}
Hooey, B.L. \& Foyle, D.C. 2007.
\textit{Aviation Safety Studies: Taxi Navigation Errors and Synthetic Vision Systems Operations}
Human Performance Modeling in Aviation.

\bibitem[Mosier ym. (1998)Mosier, Kathleen L. , Skitka, Linda J. , Heers, Susan, \& Burdick, Mark]{mosier1998}
Mosier, Kathleen L. , Skitka, Linda J. , Heers, Susan, \& Burdick, Mark 1998.
\textit{Automation Bias: Decision Making and Performance in High-Tech Cockpits}
The International Journal of Aviation Psychology, 8:1, s.~47--63.

\bibitem[Möller \& Sachs (1994)Möller \& Sachs]{mollersachs1994}
Möller, H. \& Sachs, G. 1994.
\textit{Synthetic Vision for Enhancing Poor Visibility Flight Operations}.
IEEE AES Systems Magazine, maaliskuu 1994, s.~27--33.

\bibitem[Nordwall(1993)]{nordwall1993}
Nordwall, B.D. 1993
\textit{HUD with IR System extends Pilot Vision}.
Aviation Week \& Space Technology, helmikuu 1993, s.~62--63.

\bibitem[Prinzel ym. (2013)Prinzel, Lawrence J. III, Arthur, Jarvis J. , Kramer, Lynda J. ,  Norman, Robert M. , Bailey, Randall E. , Jones, Denise R. ,  Karwac, Jerry R. Jr. , Shelton, Kevin J. \& Ellis, Kyle K. E.]{prinzel2013}
Prinzel, Lawrence J. III, Arthur, Jarvis J. , Kramer, Lynda J. ,  Norman, Robert M. , Bailey, Randall E. , Jones, Denise R. ,  Karwac, Jerry R. Jr. , Shelton, Kevin J. \& Ellis, Kyle K. E. 2013.
\textit{Flight-Deck Technologies to Enable NextGen Low Visibility Surface Operations}.
NASA Technical Reports Server (NTRS), toukokuu 2013.

\bibitem[Prinzel ym. (2004)Prinzel, Lawrence J. III, Comstock, J. Raymond Jr. , Glaab, Louis J. , Kramer, Lynda J. , Arthur, Jarvis J. & Barry, John S.]{prinzel2004}
Prinzel, Lawrence J. III, Comstock, J. Raymond Jr. , Glaab, Louis J. , Kramer, Lynda J. , Arthur, Jarvis J. \& Barry, John S. 2004.
\textit{The Efficacy of Head-Down and Head-Up Synthetic Vision Display Concepts for Retro and Forward-Fit of Commercial Aircraft}
The International Journal of Aviation Psychology, 14:1, s.~53--77.

\bibitem[Schnell ym. (2004)Schnell, Thomas,  Kwon, Yongjin, Merchant, Sohel & Etherington, Timothy]{schnell2004}
Schnell, Thomas,  Kwon, Yongjin, Merchant, Sohel \& Etherington, Timothy 2004.
\textit{Improved Flight Technical Performance in Flight Decks Equipped With Synthetic Vision Information System Displays}
The International Journal of Aviation Psychology, 14:1, s.~79--102.

\bibitem[Ververs \& Wickens (2004)Ververs, Patricia May \& Wickens, Christopher D.]{ververs1998}
Ververs, Patricia May \& Wickens, Christopher D. 1998.
\textit{Head-Up Displays: Effect of Clutter, Display Intensity, and Display Location on Pilot Performance}
The International Journal of Aviation Psychology, 8:4, s.~377--403.

\bibitem[Wickens \& Alexander(2009)Wickens, Christopher D. \& Alexander, Amy L.]{wickens2009}
Wickens, Christopher D. \& Alexander, Amy L. 2009.
\textit{Attentional Tunneling and Task Management in Synthetic Vision Displays}
The International Journal of Aviation Psychology, 19:2, s.~182--199.







% Tehdään väliaikainen "Citation needed" -lainaus, jonka voi poistaa, kun tutkielman viitteet ovat kunnossa.
\bibitem[(Lähdeviite puuttuu toistaiseksi)]{cn}



\end{thebibliography}

\end{document}
